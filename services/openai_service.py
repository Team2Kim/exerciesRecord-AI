"""
OpenAI API ì„œë¹„ìŠ¤
íŒŒì¸íŠœë‹ëœ LLMì„ í™œìš©í•œ ìš´ë™ ê´€ë ¨ AI ì„œë¹„ìŠ¤
"""

from openai import OpenAI
import os
import json
import time
import re
from typing import Optional, Dict, Any, List, Tuple, Set
from models.schemas import ComprehensiveAnalysis
from dotenv import load_dotenv
from services.exercise_rag_service import get_exercise_rag_service, ExerciseRAGService

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# ê·¼ìœ¡ ë¼ë²¨(ê¶Œì¥ í‘œì¤€ ëª…ì¹­) ë¦¬ìŠ¤íŠ¸
# ëª¨ë¸ í”„ë¡¬í”„íŠ¸ì—ì„œ ì´ ë¦¬ìŠ¤íŠ¸ ë‚´ì˜ ëª…ì¹­ë§Œ ì‚¬ìš©í•˜ë„ë¡ ê°•ì œí•©ë‹ˆë‹¤
MUSCLE_LABELS: List[str] = [
    "ê°€ë¡œëŒê¸°ì‚¬ì´ê·¼","ê°€ì‹œì‚¬ì´ê·¼","ê°€ì‹œì•„ë˜ê·¼","ê°€ì‹œìœ—ê·¼","ê°€ìë¯¸ê·¼","ê°€ìª½ë„“ì€ê·¼","ê¶ë‘¥êµ¬ë©ê·¼","ê¸´ëª¨ìŒê·¼","ê¸´ëª©ê·¼","ê¸´ë°œê°€ë½í„ê·¼",
    "ê¸´ì—„ì§€ë°œê°€ë½í„ê·¼","ë„“ì€ë“±ê·¼","ë„™ë‹¤ë¦¬ê³§ì€ê·¼","ë„™ë‹¤ë¦¬ê·¼ë§‰ê¸´ì¥ê·¼","ë„™ë‹¤ë¦¬ë„¤ê°ˆë˜ê·¼","ë„™ë‹¤ë¦¬ë‘ê°ˆë˜ê·¼","ë„™ë‹¤ë¦¬ë¹—ê·¼","ë…¸ìª½ ì†ëª© í„ê·¼",
    "ë…¸ìª½ì†ëª©êµ½í˜ê·¼","ëŒë¦¼ê·¼","ë‘ë©ì •ê°•ê·¼","ë’¤ë„™ë‹¤ë¦¬ê·¼","ë’¤ì„¸ëª¨ê·¼","ë’¤ì •ê°•ê·¼","ë“±ê°€ì‹œê·¼","ë“±ì„¸ëª¨ê·¼","ë§ˆë¦„ëª¨ê·¼","ë¨¸ë¦¬ê°€ì¥ê¸´ê·¼",
    "ë¨¸ë¦¬ë„íŒê·¼","ë¨¸ë¦¬ë°˜ê°€ì‹œê·¼","ëª¨ìŒê·¼","ëª©/ë¨¸ë¦¬ë„íŒê·¼","ëª©ë¹—ê·¼","ë­‡ê°ˆë˜ê·¼","ë°”ê¹¥ê°ˆë¹„ì‚¬ì´ê·¼","ë°˜ë§‰ëª¨ì–‘ê·¼","ë°˜í˜ì¤„ëª¨ì–‘ê·¼","ë°°ê°€ë¡œê·¼",
    "ë°°ê³§ì€ê·¼","ë°°ë°”ê¹¥ë¹—ê·¼","ë°°ë¹—ê·¼","ë°°ì†ë¹—ê·¼","ë³¼ê¸°ê·¼","ì†ëª©êµ½í˜ê·¼","ì†ëª©í„ê·¼","ì•ˆìª½ê°ˆë¹„ì‚¬ì´ê·¼","ì•ˆìª½ë„“ì€ê·¼","ì•ì„¸ëª¨ê·¼","ì•ì •ê°•ê·¼",
    "ì•í†±ë‹ˆê·¼","ì–´ê¹¨ë°‘ê·¼","ì–´ê¹¨ì„¸ëª¨ê·¼","ì–´ê¹¨ì˜¬ë¦¼ê·¼","ì—‰ë©ê´€ì ˆêµ½í˜ê·¼","ì—‰ë©ê·¼","ì—‰ë©í—ˆë¦¬ê·¼","ìœ„íŒ”ê·¼","ìœ„íŒ”ë…¸ê·¼","ìœ„íŒ”ë‘ê°ˆë˜ê·¼",
    "ìœ„íŒ”ì„¸ê°ˆë˜ê·¼","ì‘ì€ê°€ìŠ´ê·¼","ì‘ì€ë³¼ê¸°ê·¼","ì‘ì€ì›ê·¼","ì¥ë”´ì§€ê·¼","ì¥ë”´ì§€ì„¸ê°ˆë˜ê·¼","ì¤‘ê°„ë³¼ê¸°ê·¼","ì¤‘ê°„ì–´ê¹¨ì„¸ëª¨ê·¼","ì§§ì€ ëª¨ìŒê·¼",
    "ì²™ì¶”ì„¸ì›€ê·¼","í°ê°€ìŠ´ê·¼","í°ë³¼ê¸°ê·¼","í°ì›ê·¼","í°í—ˆë¦¬ê·¼","í—ˆë¦¬ê·¼","í—ˆë¦¬ë„¤ëª¨ê·¼","í—ˆë¦¬ì—‰ë©ê°ˆë¹„ê·¼"
]

# ì¼ë°˜ì ì¸ ê·¼ìœ¡ ì´ë¦„ì„ ì •í™•í•œ MUSCLE_LABELSë¡œ ë§¤í•‘í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
MUSCLE_NAME_MAPPING: Dict[str, List[str]] = {
    # ì–´ê¹¨ ê´€ë ¨
    "ì–´ê¹¨ê·¼ìœ¡": ["ì–´ê¹¨ì„¸ëª¨ê·¼", "ì–´ê¹¨ì˜¬ë¦¼ê·¼", "ì–´ê¹¨ë°‘ê·¼", "ì¤‘ê°„ì–´ê¹¨ì„¸ëª¨ê·¼"],
    "ì–´ê¹¨": ["ì–´ê¹¨ì„¸ëª¨ê·¼", "ì–´ê¹¨ì˜¬ë¦¼ê·¼", "ì–´ê¹¨ë°‘ê·¼"],
    
    # íŒ” ê´€ë ¨
    "íŒ”ê·¼ìœ¡": ["ìœ„íŒ”ë‘ê°ˆë˜ê·¼", "ìœ„íŒ”ì„¸ê°ˆë˜ê·¼", "ìœ„íŒ”ê·¼", "ìœ„íŒ”ë…¸ê·¼"],
    "íŒ”": ["ìœ„íŒ”ë‘ê°ˆë˜ê·¼", "ìœ„íŒ”ì„¸ê°ˆë˜ê·¼", "ìœ„íŒ”ê·¼"],
    "ì‚¼ë‘": ["ìœ„íŒ”ì„¸ê°ˆë˜ê·¼"],
    "ì´ë‘": ["ìœ„íŒ”ë‘ê°ˆë˜ê·¼"],
    
    # ë³µê·¼ ê´€ë ¨
    "ë³µê·¼": ["ë°°ê³§ì€ê·¼", "ë°°ê°€ë¡œê·¼", "ë°°ë°”ê¹¥ë¹—ê·¼", "ë°°ì†ë¹—ê·¼"],
    "ë³µë¶€": ["ë°°ê³§ì€ê·¼", "ë°°ê°€ë¡œê·¼"],
    "ì½”ì–´": ["ë°°ê³§ì€ê·¼", "ë°°ê°€ë¡œê·¼", "í—ˆë¦¬ê·¼"],
    
    # ì¢…ì•„ë¦¬ ê´€ë ¨
    "ì¢…ì•„ë¦¬ê·¼ìœ¡": ["ì¥ë”´ì§€ê·¼", "ì¥ë”´ì§€ì„¸ê°ˆë˜ê·¼", "ë’¤ì •ê°•ê·¼"],
    "ì¢…ì•„ë¦¬": ["ì¥ë”´ì§€ê·¼", "ì¥ë”´ì§€ì„¸ê°ˆë˜ê·¼"],
    
    # ë‘”ê·¼/ë³¼ê¸°ê·¼ ê´€ë ¨
    "ë³¼ê¸°ê·¼": ["í°ë³¼ê¸°ê·¼", "ì¤‘ê°„ë³¼ê¸°ê·¼", "ì‘ì€ë³¼ê¸°ê·¼"],
    "ë‘”ê·¼": ["í°ë³¼ê¸°ê·¼", "ì¤‘ê°„ë³¼ê¸°ê·¼", "ì‘ì€ë³¼ê¸°ê·¼"],
    
    # ê°€ìŠ´ ê´€ë ¨
    "ê°€ìŠ´": ["í°ê°€ìŠ´ê·¼", "ì‘ì€ê°€ìŠ´ê·¼"],
    
    # ë“± ê´€ë ¨
    "ë“±": ["ë„“ì€ë“±ê·¼", "ë“±ì„¸ëª¨ê·¼", "ë“±ê°€ì‹œê·¼"],
    
    # í•˜ì²´ ê´€ë ¨
    "í•˜ì²´": ["ë„™ë‹¤ë¦¬ë„¤ê°ˆë˜ê·¼", "ë„™ë‹¤ë¦¬ë‘ê°ˆë˜ê·¼", "ë’¤ë„™ë‹¤ë¦¬ê·¼", "í°ë³¼ê¸°ê·¼", "ì¤‘ê°„ë³¼ê¸°ê·¼", "ì‘ì€ë³¼ê¸°ê·¼"],
    "í—ˆë²…ì§€": ["ë„™ë‹¤ë¦¬ë„¤ê°ˆë˜ê·¼", "ë„™ë‹¤ë¦¬ë‘ê°ˆë˜ê·¼", "ë’¤ë„™ë‹¤ë¦¬ê·¼"],
    "ëŒ€í‡´": ["ë„™ë‹¤ë¦¬ë„¤ê°ˆë˜ê·¼", "ë„™ë‹¤ë¦¬ë‘ê°ˆë˜ê·¼"],
    
    # í—ˆë¦¬ ê´€ë ¨
    "í—ˆë¦¬": ["í°í—ˆë¦¬ê·¼", "í—ˆë¦¬ê·¼", "í—ˆë¦¬ë„¤ëª¨ê·¼"],
}


def validate_and_map_muscles(muscle_names: List[str]) -> List[str]:
    """
    ê·¼ìœ¡ ì´ë¦„ ëª©ë¡ì„ ê²€ì¦í•˜ê³  MUSCLE_LABELSì— ë§ê²Œ ë§¤í•‘í•©ë‹ˆë‹¤.
    
    Args:
        muscle_names: ê²€ì¦í•  ê·¼ìœ¡ ì´ë¦„ ëª©ë¡
        
    Returns:
        MUSCLE_LABELSì— í¬í•¨ëœ ìœ íš¨í•œ ê·¼ìœ¡ ì´ë¦„ ëª©ë¡
    """
    validated_muscles = []
    
    for muscle in muscle_names:
        muscle = muscle.strip()
        
        # ì´ë¯¸ MUSCLE_LABELSì— ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        if muscle in MUSCLE_LABELS:
            validated_muscles.append(muscle)
            continue
        
        # ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ì—ì„œ ì°¾ê¸°
        if muscle in MUSCLE_NAME_MAPPING:
            # ë§¤í•‘ëœ ê·¼ìœ¡ ì¤‘ ì²« ë²ˆì§¸ ê²ƒì„ ì‚¬ìš© (ë˜ëŠ” ëª¨ë‘ ì¶”ê°€ ê°€ëŠ¥)
            mapped = MUSCLE_NAME_MAPPING[muscle]
            validated_muscles.extend(mapped[:1])  # ì²« ë²ˆì§¸ ë§¤í•‘ë§Œ ì‚¬ìš©
            continue
        
        # ë¶€ë¶„ ë§¤ì¹­ìœ¼ë¡œ ì°¾ê¸° (ì˜ˆ: "ì–´ê¹¨"ê°€ í¬í•¨ëœ ê²½ìš°)
        found = False
        for label in MUSCLE_LABELS:
            if muscle in label or label in muscle:
                validated_muscles.append(label)
                found = True
                break
        
        # ë§¤í•‘ë˜ì§€ ì•Šìœ¼ë©´ ë¬´ì‹œ (ë¡œê·¸ëŠ” ë‚¨ê¸°ì§€ ì•ŠìŒ)
        if not found:
            # ìœ ì‚¬í•œ ê·¼ìœ¡ ì°¾ê¸° (í‚¤ì›Œë“œ ê¸°ë°˜)
            muscle_lower = muscle.lower()
            for key, mapped_list in MUSCLE_NAME_MAPPING.items():
                if key in muscle_lower or muscle_lower in key:
                    validated_muscles.extend(mapped_list[:1])
                    found = True
                    break
    
    # ì¤‘ë³µ ì œê±° ë° ìˆœì„œ ìœ ì§€
    seen = set()
    result = []
    for muscle in validated_muscles:
        if muscle not in seen:
            seen.add(muscle)
            result.append(muscle)
    
    return result


class OpenAIService:
    """OpenAI API ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        # API í‚¤ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œí•˜ëŠ” ê²ƒì´ ì•ˆì „í•©ë‹ˆë‹¤
        api_key = os.getenv("OPENAI_API_KEY", "")
        self.client = OpenAI(api_key=api_key) if api_key else None
        self.exercise_rag: Optional[ExerciseRAGService] = None
        self.exercise_rag_error: Optional[str] = None

        try:
            self.exercise_rag = get_exercise_rag_service()
        except Exception as exc:
            self.exercise_rag_error = str(exc)
    
    @staticmethod
    def _clean_user_profile(
        user_profile: Optional[Dict[str, str]]
    ) -> Dict[str, str]:
        """ì‚¬ìš©ì í”„ë¡œí•„ì—ì„œ 'ì„ íƒ ì•ˆ í•¨' ë˜ëŠ” ë¹ˆ ê°’ì„ ì œê±°"""
        
        if not user_profile:
            return {}

        allowed_keys = {"targetGroup", "fitnessLevelName", "fitnessFactorName"}
        cleaned: Dict[str, str] = {}
        for key in allowed_keys:
            value = user_profile.get(key)
            if not value:
                continue
            normalized = value.strip()
            if not normalized or normalized == "ì„ íƒ ì•ˆ í•¨":
                continue
            cleaned[key] = normalized
        return cleaned

    def _build_rag_filter_options(
        self, profile_data: Optional[Dict[str, str]]
    ) -> Dict[str, Optional[Any]]:
        """ì‚¬ìš©ì í”„ë¡œí•„ ê¸°ë°˜ RAG í•„í„° ì˜µì…˜ êµ¬ì„±"""
        filters: Dict[str, Optional[Any]] = {
            "target_group_filter": None,
            "exclude_target_groups": None,
            "fitness_factor_filter": None,
            "exclude_fitness_factors": None,
        }

        if not profile_data:
            return filters

        target_group = profile_data.get("targetGroup")
        if target_group == "ì„±ì¸":
            filters["exclude_target_groups"] = ["ìœ ì†Œë…„", "ë…¸ì¸"]
        elif target_group:
            filters["target_group_filter"] = target_group

        fitness_factor = profile_data.get("fitnessFactorName")
        if fitness_factor:
            filters["fitness_factor_filter"] = fitness_factor
            if "ê·¼ë ¥" in fitness_factor or "ê·¼ì§€êµ¬ë ¥" in fitness_factor:
                filters["exclude_fitness_factors"] = ["ìœ ì—°ì„±"]

        return filters

    def _build_profile_prefix(self, profile_data: Optional[Dict[str, str]]) -> str:
        """RAG ê²€ìƒ‰ ì¿¼ë¦¬ìš© ì‚¬ìš©ì í”„ë¡œí•„ í…ìŠ¤íŠ¸"""
        if not profile_data:
            return ""

        profile_parts: List[str] = []
        if profile_data.get("targetGroup"):
            profile_parts.append(profile_data["targetGroup"])
        if profile_data.get("fitnessLevelName"):
            profile_parts.append(profile_data["fitnessLevelName"])
        if profile_data.get("fitnessFactorName"):
            profile_parts.append(profile_data["fitnessFactorName"])

        return " ".join(profile_parts).strip()

    def _expand_muscle_aliases(self, muscle: str) -> List[str]:
        """íŠ¹ì • ê·¼ìœ¡ëª…ê³¼ ì—°ê´€ëœ ë‹¤ì–‘í•œ ëª…ì¹­/ì„¸ë¶€ ê·¼ìœ¡ì„ ë°˜í™˜"""
        aliases = {muscle.strip()}

        if muscle in MUSCLE_NAME_MAPPING:
            aliases.update(MUSCLE_NAME_MAPPING[muscle])

        for label in MUSCLE_LABELS:
            if muscle in label or label in muscle:
                aliases.add(label)

        return [alias for alias in aliases if alias]

    def _metadata_matches_muscle(
        self, meta_muscles: Any, alias_tokens: List[str]
    ) -> bool:
        """ë©”íƒ€ë°ì´í„°ì˜ ê·¼ìœ¡ ì •ë³´ê°€ ì›í•˜ëŠ” ê·¼ìœ¡ ëª…ì¹­ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸"""
        if not meta_muscles or not alias_tokens:
            return False

        if isinstance(meta_muscles, str):
            normalized = re.split(r"[,\n/]", meta_muscles)
            candidates = [token.strip().lower() for token in normalized if token.strip()]
        elif isinstance(meta_muscles, list):
            candidates = [str(token).strip().lower() for token in meta_muscles if token]
        else:
            candidates = [str(meta_muscles).strip().lower()]

        alias_set = {alias.strip().lower() for alias in alias_tokens if alias}
        if not alias_set:
            return False

        for candidate in candidates:
            for alias in alias_set:
                if not alias or not candidate:
                    continue
                if alias in candidate or candidate in alias:
                    return True

        return False

    def _format_user_profile_block(self, profile: Dict[str, str]) -> str:
        """í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©í•  ì‚¬ìš©ì í”„ë¡œí•„ ì„¤ëª…ì„ ìƒì„±"""
        if not profile:
            return (
                "ì œê³µë˜ì§€ ì•ŠìŒ (ì¼ë°˜ì ì¸ ëŒ€ìƒ/ìˆ˜ì¤€/ëª©ì ì„ ê¸°ì¤€ìœ¼ë¡œ ì•ˆì „í•œ ìš´ë™ì„ ì¶”ì²œí•˜ì„¸ìš”)."
            )

        label_map = {
            "targetGroup": "ëŒ€ìƒ ì—°ë ¹ëŒ€",
            "fitnessLevelName": "ìš´ë™ ìˆ˜ì¤€",
            "fitnessFactorName": "ìš´ë™ ëª©ì ",
        }
        lines = []
        for key, label in label_map.items():
            if profile.get(key):
                lines.append(f"- {label}: {profile[key]}")

        lines.append(
            "- ìœ„ ì¡°ê±´ì— ë§ì¶° ìš´ë™ ê°•ë„, ìš´ë™ ì¢…ë¥˜, ì£¼ì˜ì‚¬í•­ì„ ì¡°ì •í•˜ê³  ë¶€ì ì ˆí•œ ì›€ì§ì„ì€ í”¼í•˜ì„¸ìš”."
        )
        return "\n".join(lines)
    
    def _repair_json_response(self, raw_response: str, json_error: json.JSONDecodeError) -> Optional[Dict[str, Any]]:
        """JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë³µêµ¬ ì‹œë„"""
        try:
            # ì—ëŸ¬ ìœ„ì¹˜ í™•ì¸
            error_pos = getattr(json_error, 'pos', None)
            error_msg = str(json_error)
            
            print(f"[JSON ë³µêµ¬] ì‹œì‘ - ì—ëŸ¬ ìœ„ì¹˜: {error_pos}, ë©”ì‹œì§€: {error_msg[:100]}")
            
            # ë¬¸ìì—´ ì¢…ë£Œë˜ì§€ ì•Šì€ ê²½ìš° ì²˜ë¦¬
            if "Unterminated string" in error_msg:
                # ë°©ë²• 1: ì—ëŸ¬ ìœ„ì¹˜ ì´ì „ì˜ ë§ˆì§€ë§‰ ì™„ì „í•œ ë¬¸ìì—´ í•„ë“œê¹Œì§€ ì°¾ì•„ì„œ ì œê±°
                check_limit = error_pos if error_pos else len(raw_response)
                
                # ì—ëŸ¬ ìœ„ì¹˜ ì´ì „ì—ì„œ ë§ˆì§€ë§‰ ì™„ì „í•œ í•„ë“œ ë ìœ„ì¹˜ ì°¾ê¸°
                # ì—­ìˆœìœ¼ë¡œ íƒìƒ‰í•˜ì—¬ ì™„ì „í•œ JSON êµ¬ì¡° ì°¾ê¸°
                for cut_pos in range(check_limit - 1, max(0, check_limit - 500), -1):
                    # cut_pos ì´ì „ê¹Œì§€ì˜ ë¬¸ìì—´ë¡œ í…ŒìŠ¤íŠ¸
                    test_str = raw_response[:cut_pos]
                    
                    # ë§ˆì§€ë§‰ ë¶ˆì™„ì „í•œ í•„ë“œ ì œê±° ì‹œë„
                    # ë§ˆì§€ë§‰ ì‰¼í‘œë‚˜ ì½œë¡  ì´í›„ì˜ ë¶ˆì™„ì „í•œ ë¶€ë¶„ ì œê±°
                    last_comma = test_str.rfind(',')
                    last_colon = test_str.rfind(':')
                    last_quote = test_str.rfind('"')
                    
                    # ë§ˆì§€ë§‰ ì™„ì „í•œ í•„ë“œ ë ì°¾ê¸°
                    if last_comma > last_colon and last_comma > 0:
                        # ì‰¼í‘œ ì´í›„ì˜ ë¶ˆì™„ì „í•œ ë¶€ë¶„ ì œê±°
                        test_str = test_str[:last_comma]
                    elif last_colon > 0:
                        # ì½œë¡  ì´í›„ì˜ ë¶ˆì™„ì „í•œ ë¶€ë¶„ ì œê±°
                        # ì½œë¡  ì´ì „ì˜ í•„ë“œëª…ê¹Œì§€ í¬í•¨
                        field_start = test_str.rfind('"', 0, last_colon)
                        if field_start > 0:
                            test_str = test_str[:field_start]
                    
                    # ì¤‘ê´„í˜¸/ëŒ€ê´„í˜¸ ê· í˜• ë§ì¶”ê¸°
                    open_braces = test_str.count('{') - test_str.count('}')
                    open_brackets = test_str.count('[') - test_str.count(']')
                    
                    if open_braces > 0:
                        test_str += '}' * open_braces
                    if open_brackets > 0:
                        test_str += ']' * open_brackets
                    
                    # ë§ˆì§€ë§‰ ì‰¼í‘œ ì œê±° (JSON ê°ì²´ ëì—ëŠ” ì‰¼í‘œê°€ ì—†ì–´ì•¼ í•¨)
                    test_str = test_str.rstrip().rstrip(',')
                    
                    # ë‹«ëŠ” ì¤‘ê´„í˜¸ ì¶”ê°€
                    if not test_str.rstrip().endswith('}'):
                        test_str += '}'
                    
                    try:
                        result = json.loads(test_str)
                        print(f"[JSON ë³µêµ¬] âœ… ì„±ê³µ - ë¶ˆì™„ì „í•œ í•„ë“œ ì œê±° í›„ íŒŒì‹± (ê¸¸ì´: {len(test_str)})")
                        return result
                    except:
                        continue
                
                # ë°©ë²• 2: ì—ëŸ¬ ìœ„ì¹˜ ì´ì „ì˜ ì™„ì „í•œ JSON êµ¬ì¡° ì°¾ê¸°
                open_braces = 0
                open_brackets = 0
                in_string = False
                escape_next = False
                last_valid_pos = 0
                
                for i, char in enumerate(raw_response[:check_limit]):
                    if escape_next:
                        escape_next = False
                        continue
                    if char == '\\':
                        escape_next = True
                        continue
                    if char == '"' and not escape_next:
                        in_string = not in_string
                        continue
                    if in_string:
                        continue
                    
                    if char == '{':
                        open_braces += 1
                    elif char == '}':
                        open_braces -= 1
                        if open_braces == 0 and open_brackets == 0:
                            last_valid_pos = i + 1
                    elif char == '[':
                        open_brackets += 1
                    elif char == ']':
                        open_brackets -= 1
                        if open_braces == 0 and open_brackets == 0:
                            last_valid_pos = i + 1
                
                # ì™„ì „í•œ JSON êµ¬ì¡°ë¥¼ ì°¾ì•˜ìœ¼ë©´ ê·¸ ë¶€ë¶„ë§Œ íŒŒì‹±
                if last_valid_pos > 100:
                    truncated = raw_response[:last_valid_pos]
                    try:
                        result = json.loads(truncated)
                        print(f"[JSON ë³µêµ¬] âœ… ì„±ê³µ - ì™„ì „í•œ JSON êµ¬ì¡° íŒŒì‹± (ê¸¸ì´: {last_valid_pos})")
                        return result
                    except Exception as parse_err:
                        print(f"[JSON ë³µêµ¬] âš ï¸ ì™„ì „í•œ êµ¬ì¡° íŒŒì‹± ì‹¤íŒ¨: {str(parse_err)}")
            
            # ì¤‘ê´„í˜¸ ê· í˜•ì´ ë§ì§€ ì•ŠëŠ” ê²½ìš°
            brace_count = raw_response.count('{') - raw_response.count('}')
            bracket_count = raw_response.count('[') - raw_response.count(']')
            
            if brace_count > 0 or bracket_count > 0:
                print(f"[JSON ë³µêµ¬] ì¤‘ê´„í˜¸ ë¶ˆê· í˜• - ì¤‘ê´„í˜¸: {brace_count}, ëŒ€ê´„í˜¸: {bracket_count}")
                # ë¨¼ì € ë¶ˆì™„ì „í•œ ë¬¸ìì—´ í•„ë“œ ì œê±° ì‹œë„
                repaired = raw_response
                # ë§ˆì§€ë§‰ ë¶ˆì™„ì „í•œ í•„ë“œ ì œê±°
                last_colon = repaired.rfind(':')
                if last_colon > 0:
                    # ì½œë¡  ì´í›„ì˜ ë¶ˆì™„ì „í•œ ë¶€ë¶„ ì œê±°
                    field_start = repaired.rfind('"', 0, last_colon)
                    if field_start > 0:
                        repaired = repaired[:field_start]
                        # ë§ˆì§€ë§‰ ì‰¼í‘œ ì œê±°
                        repaired = repaired.rstrip().rstrip(',')
                
                # ë‹«íˆì§€ ì•Šì€ ì¤‘ê´„í˜¸/ëŒ€ê´„í˜¸ ì¶”ê°€
                open_braces = repaired.count('{') - repaired.count('}')
                open_brackets = repaired.count('[') - repaired.count(']')
                repaired += '}' * open_braces
                repaired += ']' * open_brackets
                
                try:
                    result = json.loads(repaired)
                    print(f"[JSON ë³µêµ¬] âœ… ì„±ê³µ - ì¤‘ê´„í˜¸ ê· í˜• ë³µêµ¬")
                    return result
                except Exception as repair_err:
                    print(f"[JSON ë³µêµ¬] âš ï¸ ì¤‘ê´„í˜¸ ë³µêµ¬ ì‹¤íŒ¨: {str(repair_err)}")
            
            print(f"[JSON ë³µêµ¬] âŒ ëª¨ë“  ë³µêµ¬ ì‹œë„ ì‹¤íŒ¨")
            return None
        except Exception as e:
            print(f"[JSON ë³µêµ¬] ë³µêµ¬ ì‹œë„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            import traceback
            traceback.print_exc()
            return None
        
    def generate_workout_recommendation(
        self, 
        analysis_data: ComprehensiveAnalysis,
        user_preferences: Optional[Dict[str, Any]] = None,
        model: str = "gpt-4o-mini"
    ) -> Dict[str, Any]:
        """
        ìš´ë™ ì¼ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AI ì¶”ì²œì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            analysis_data: ì¢…í•© ë¶„ì„ ê²°ê³¼
            user_preferences: ì‚¬ìš©ì ì„ í˜¸ë„ (ì„ íƒì )
            model: ì‚¬ìš©í•  OpenAI ëª¨ë¸ (ê¸°ë³¸ê°’: "gpt-4o-mini")
            
        Returns:
            Dict[str, Any]: AI ì¶”ì²œ ê²°ê³¼
        """
        
        if not self.client:
            return {
                "success": False,
                "message": "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "fallback_recommendations": analysis_data.insights.recommendations
            }
        
        try:
            # ë¶„ì„ ê²°ê³¼ë¥¼ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜
            prompt = self._create_workout_analysis_prompt(analysis_data)
            
            # OpenAI API í˜¸ì¶œ - ê³ ì •ëœ JSON í˜•ì‹
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {
                        "role": "system",
                        "content": """ë‹¹ì‹ ì€ ì „ë¬¸ ìš´ë™ ì½”ì¹˜ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:

{
    "pattern_analysis": {
        "strengths": "í˜„ì¬ ìš´ë™ íŒ¨í„´ì˜ ì¥ì ",
        "weaknesses": "ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„"
    },
    "recommendations": {
        "focus_areas": ["ê°œì„  í¬ì¸íŠ¸1", "ê°œì„  í¬ì¸íŠ¸2"],
        "workout_routine": "ì¶”ì²œ ìš´ë™ ë£¨í‹´ ì„¤ëª…",
        "tips": "ì£¼ì˜ì‚¬í•­ ë° ë¶€ìƒ ì˜ˆë°© íŒ"
    },
    "next_target_muscles": ["ê·¼ìœ¡ëª…1", "ê·¼ìœ¡ëª…2"]
    "encouragement": "ê²©ë ¤ ë©”ì‹œì§€"
}

í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ê²©ë ¤í•˜ëŠ” í†¤ì„ ìœ ì§€í•˜ë©´ì„œ ë°˜ë“œì‹œ ìœ„ JSON êµ¬ì¡°ë¥¼ ë”°ë¥´ì„¸ìš”.

âš ï¸ ì¤‘ìš”: next_target_muscles í•„ë“œëŠ” ë°˜ë“œì‹œ ì•„ë˜ ê·¼ìœ¡ ë¼ë²¨ ëª©ë¡ì— ì •í™•íˆ í¬í•¨ëœ ì´ë¦„ë§Œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
ë‹¤ë¥¸ ì´ë¦„(ì˜ˆ: "ì–´ê¹¨ê·¼ìœ¡", "íŒ”ê·¼ìœ¡", "ë³µê·¼", "ì¢…ì•„ë¦¬ê·¼ìœ¡" ë“±)ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
ë°˜ë“œì‹œ ì•„ë˜ ëª©ë¡ì—ì„œ ì •í™•í•œ ê·¼ìœ¡ëª…ì„ ì„ íƒí•˜ì„¸ìš”."""
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.7,
                max_tokens=1000,
                response_format={"type": "json_object"}  # JSON í˜•ì‹ ê³ ì •
            )
            
            ai_recommendation = response.choices[0].message.content
            
            # JSON ì‘ë‹µ íŒŒì‹±
            try:
                parsed_recommendation = json.loads(ai_recommendation)
                
                # next_target_muscles ê²€ì¦ ë° ë§¤í•‘
                if "next_target_muscles" in parsed_recommendation:
                    original_muscles = parsed_recommendation["next_target_muscles"]
                    if isinstance(original_muscles, list):
                        validated_muscles = validate_and_map_muscles(original_muscles)
                        parsed_recommendation["next_target_muscles"] = validated_muscles
            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë¬¸ìì—´ ë°˜í™˜
                parsed_recommendation = {"raw_response": ai_recommendation}
            
            return {
                "success": True,
                "ai_recommendation": parsed_recommendation,  # íŒŒì‹±ëœ JSON ë°˜í™˜
                "original_insights": {
                    "overworked_parts": analysis_data.insights.overworked_parts,
                    "underworked_parts": analysis_data.insights.underworked_parts,
                    "balance_score": analysis_data.insights.balance_score
                }
            }
            
        except Exception as e:
            return {
                "success": False,
                "message": f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "fallback_recommendations": analysis_data.insights.recommendations
            }
    
    def analyze_workout_log(
        self,
        workout_log: Dict[str, Any],
        model: str = "gpt-4o-mini",
        user_profile: Optional[Dict[str, str]] = None,
    ) -> Dict[str, Any]:
        """
        ìš´ë™ ì¼ì§€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  í‰ê°€í•©ë‹ˆë‹¤.
        
        Args:
            workout_log: ì™¸ë¶€ APIì—ì„œ ë°›ì€ ìš´ë™ ì¼ì§€ ë°ì´í„°
            model: ì‚¬ìš©í•  OpenAI ëª¨ë¸ (ê¸°ë³¸ê°’: "gpt-4o-mini")
            user_profile: ì‚¬ìš©ì í”„ë¡œí•„ ì •ë³´ (targetGroup, fitnessLevelName, fitnessFactorName)
            
        Returns:
            Dict[str, Any]: AI ë¶„ì„ ê²°ê³¼
        """
        
        if not self.client:
            return {
                "success": False,
                "message": "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            }
        
        try:
            # ë¡œê·¸ ë°ì´í„°ë¥¼ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜
            profile_data = self._clean_user_profile(user_profile)
            prompt = self._create_log_analysis_prompt(workout_log, profile_data)
            
            # OpenAI API í˜¸ì¶œ - ê³ ì •ëœ í˜•ì‹ ì‚¬ìš©
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {
                        "role": "system",
                        "content": """ë‹¹ì‹ ì€ ì „ë¬¸ ìš´ë™ ì½”ì¹˜ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:

{
    "workout_evaluation": "ìš´ë™ ê°•ë„ì™€ ì‹œê°„ì— ëŒ€í•œ í‰ê°€ ë‚´ìš©",
    "target_muscles": "íƒ€ê²Ÿ ê·¼ìœ¡ê³¼ íš¨ê³¼ ë¶„ì„ ë‚´ìš©",
    "recommendations": {
        "next_workout": "ë‹¤ìŒ ìš´ë™ ì¶”ì²œ",
        "improvements": "ê°œì„  í¬ì¸íŠ¸",
        "precautions": "ì£¼ì˜ì‚¬í•­"
    },
    "next_target_muscles": ["ê·¼ìœ¡ëª…1", "ê·¼ìœ¡ëª…2", "ê·¼ìœ¡ëª…3"],
    "encouragement": "ê²©ë ¤ ë©”ì‹œì§€"
}

ì¹œê·¼í•˜ê³  ê²©ë ¤í•˜ëŠ” í†¤ì„ ìœ ì§€í•˜ë©´ì„œ ë°˜ë“œì‹œ ìœ„ JSON êµ¬ì¡°ë¥¼ ë”°ë¥´ì„¸ìš”.

next_workoutì—ì„œ ì¶”ì²œí•˜ëŠ” í›ˆë ¨ê³¼ next_target_musclesì— í¬í•¨ëœ ê·¼ìœ¡ì€ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
ì˜ˆë¥¼ ë“¤ì–´ next_workoutì—ì„œ ë‹¤ìŒ í›ˆë ¨ìœ¼ë¡œ í•˜ì²´ë¥¼ ì¶”ì²œí•œë‹¤ë©´ next_target_musclesì—ëŠ” í•˜ì²´ ê·¼ìœ¡ì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

âš ï¸ ì¤‘ìš”: next_target_muscles í•„ë“œëŠ” ë°˜ë“œì‹œ ì•„ë˜ ê·¼ìœ¡ ë¼ë²¨ ëª©ë¡ì— ì •í™•íˆ í¬í•¨ëœ ì´ë¦„ë§Œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
ë‹¤ë¥¸ ì´ë¦„(ì˜ˆ: "ì–´ê¹¨ê·¼ìœ¡", "íŒ”ê·¼ìœ¡", "ë³µê·¼", "ì¢…ì•„ë¦¬ê·¼ìœ¡" ë“±)ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
ë°˜ë“œì‹œ ì•„ë˜ ëª©ë¡ì—ì„œ ì •í™•í•œ ê·¼ìœ¡ëª…ì„ ì„ íƒí•˜ì„¸ìš”."""
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.8,
                max_tokens=1500,
                response_format={"type": "json_object"}  # JSON í˜•ì‹ ê³ ì •
            )
            
            ai_analysis = response.choices[0].message.content
            
            # JSON ì‘ë‹µ íŒŒì‹±
            try:
                parsed_analysis = json.loads(ai_analysis)
                
                # next_target_muscles ê²€ì¦ ë° ë§¤í•‘
                if "next_target_muscles" in parsed_analysis:
                    original_muscles = parsed_analysis["next_target_muscles"]
                    if isinstance(original_muscles, list):
                        validated_muscles = validate_and_map_muscles(original_muscles)
                        parsed_analysis["next_target_muscles"] = validated_muscles
                        # next_target ê·¼ìœ¡ì— ë§ëŠ” RAG ìš´ë™ ì¶”ê°€
                        rag_exercises = self._search_exercises_for_muscles(
                            validated_muscles,
                            profile_data,
                            per_muscle=3,
                        )
                        if rag_exercises:
                            parsed_analysis["next_target_exercises"] = rag_exercises
            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë¬¸ìì—´ ë°˜í™˜
                parsed_analysis = {"raw_response": ai_analysis}
            
            return {
                "success": True,
                "analysis": parsed_analysis,  # íŒŒì‹±ëœ JSON ë°˜í™˜
                "model": model
            }
            
        except Exception as e:
            return {
                "success": False,
                "message": f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }
    
    def recommend_workout_routine(
        self, 
        workout_log: Dict[str, Any],
        days: int = 7,
        frequency: int = 4,
        model: str = "gpt-4o-mini",
        user_profile: Optional[Dict[str, str]] = None,
    ) -> Dict[str, Any]:
        """
        ìš´ë™ ì¼ì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§ì¶¤ ìš´ë™ ë£¨í‹´ì„ ì¶”ì²œí•©ë‹ˆë‹¤.
        
        Args:
            workout_log: ì™¸ë¶€ APIì—ì„œ ë°›ì€ ìš´ë™ ì¼ì§€ ë°ì´í„°
            days: ë‹¤ìŒ ë©°ì¹ ê°„ì˜ ë£¨í‹´ (ê¸°ë³¸ 7ì¼)
            frequency: ì£¼ê°„ ìš´ë™ ë¹ˆë„
            model: ì‚¬ìš©í•  OpenAI ëª¨ë¸ (ê¸°ë³¸ê°’: "gpt-4o-mini")
            user_profile: ì‚¬ìš©ì í”„ë¡œí•„ ì •ë³´ (targetGroup, fitnessLevelName, fitnessFactorName)
            
        Returns:
            Dict[str, Any]: AI ì¶”ì²œ ë£¨í‹´
        """
        
        if not self.client:
            return {
                "success": False,
                "message": "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            }
        
        try:
            rag_candidates = self._get_rag_candidates_for_routine(workout_log, frequency, user_profile=user_profile)

            # ë£¨í‹´ ì¶”ì²œ í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._create_routine_recommendation_prompt(
                workout_log, days, frequency, rag_candidates, user_profile=user_profile
            )
            
            # OpenAI API í˜¸ì¶œ - ê³ ì •ëœ JSON í˜•ì‹
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {
                        "role": "system",
                        "content": f"""ë‹¹ì‹ ì€ ì „ë¬¸ ìš´ë™ ì½”ì¹˜ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:

{{
    "workout_goal": "ìš´ë™ ëª©í‘œì™€ ë°©í–¥ì„±",
    "weekly_overview": {{
        "day_1": "ì²«ì§¸ ë‚  ìš´ë™ ë¶€ìœ„ì™€ ëª©í‘œ ìš”ì•½",
        "day_2": "ë‘˜ì§¸ ë‚  ìš´ë™ ë¶€ìœ„ì™€ ëª©í‘œ ìš”ì•½",
        "day_3": "ì…‹ì§¸ ë‚  ìš´ë™ ë¶€ìœ„ì™€ ëª©í‘œ ìš”ì•½",
        "day_4": "ë„·ì§¸ ë‚  ìš´ë™ ë¶€ìœ„ì™€ ëª©í‘œ ìš”ì•½"
    }},
    "daily_routines": [
        {{
            "day": 1,
            "focus": "í•´ë‹¹ ë‚ ì§œì˜ í•µì‹¬ ëª©í‘œ ìš”ì•½",
            "target_body_parts": ["ë¶€ìœ„1", "ë¶€ìœ„2"],
            "exercises": [
                {{
                    "exercise_id": "í›„ë³´ ë°ì´í„°ì˜ exercise_id ê°’",
                    "title": "í›„ë³´ ë°ì´í„°ì˜ title ê°’ (name í•„ë“œ ëŒ€ì‹  title ì‚¬ìš©)",
                    "standard_title": "í›„ë³´ ë°ì´í„°ì˜ standard_title ê°’",
                    "sets": "ì„¸íŠ¸ ìˆ˜",
                    "reps": "ë°˜ë³µ íšŸìˆ˜",
                    "rest": "íœ´ì‹ ì‹œê°„",
                    "notes": "ì‹¤í–‰ íŒ",
                    "body_part": "í›„ë³´ ë°ì´í„°ì˜ body_part ê°’",
                    "exercise_tool": "í›„ë³´ ë°ì´í„°ì˜ exercise_tool ê°’",
                    "description": "í›„ë³´ ë°ì´í„°ì˜ description ê°’",
                    "muscles": "í›„ë³´ ë°ì´í„°ì˜ muscles ê°’",
                    "target_group": "í›„ë³´ ë°ì´í„°ì˜ target_group ê°’",
                    "fitness_factor_name": "í›„ë³´ ë°ì´í„°ì˜ fitness_factor_name ê°’",
                    "fitness_level_name": "í›„ë³´ ë°ì´í„°ì˜ fitness_level_name ê°’",
                    "video_url": "í›„ë³´ ë°ì´í„°ì—ì„œ ì œê³µí•œ ì˜ìƒ ë§í¬",
                    "video_length_seconds": "í›„ë³´ ë°ì´í„°ì˜ video_length_seconds ê°’",
                    "image_url": "í›„ë³´ ë°ì´í„°ì˜ image_url ê°’"
                }}
            ],
            "total_duration": "ì˜ˆìƒ ì‹œê°„(ë¶„)",
            "reference_videos": [
                {{
                    "title": "í›„ë³´ ìš´ë™ëª…",
                    "video_url": "ì˜ìƒ ë§í¬",
                    "why": "ì´ ì˜ìƒì„ ì¶”ì²œí•˜ëŠ” ì´ìœ "
                }}
            ]
        }}
    ],
    "tips_and_precautions": "ì£¼ì˜ì‚¬í•­ê³¼ íŒ",
    "suggested_exercises": [
        {{
            "exercise_id": "í›„ë³´ ë°ì´í„°ì˜ exercise_id ê°’",
            "title": "í›„ë³´ ë°ì´í„°ì˜ title ê°’",
            "standard_title": "í›„ë³´ ë°ì´í„°ì˜ standard_title ê°’",
            "body_part": "í›„ë³´ ë°ì´í„°ì˜ body_part ê°’",
            "exercise_tool": "í›„ë³´ ë°ì´í„°ì˜ exercise_tool ê°’",
            "description": "í›„ë³´ ë°ì´í„°ì˜ description ê°’",
            "muscles": "í›„ë³´ ë°ì´í„°ì˜ muscles ê°’",
            "target_group": "í›„ë³´ ë°ì´í„°ì˜ target_group ê°’",
            "fitness_factor_name": "í›„ë³´ ë°ì´í„°ì˜ fitness_factor_name ê°’",
            "fitness_level_name": "í›„ë³´ ë°ì´í„°ì˜ fitness_level_name ê°’",
            "video_url": "í›„ë³´ ë°ì´í„°ì˜ video_url ê°’",
            "video_length_seconds": "í›„ë³´ ë°ì´í„°ì˜ video_length_seconds ê°’",
            "image_url": "í›„ë³´ ë°ì´í„°ì˜ image_url ê°’",
            "why": "ì¶”ì²œ ì´ìœ "
        }}
    ],
    "next_target_muscles": ["ê·¼ìœ¡ëª…1", "ê·¼ìœ¡ëª…2", "ê·¼ìœ¡ëª…3"]
}}

âš ï¸ ë§¤ìš° ì¤‘ìš” - RAG í›„ë³´ ë°ì´í„° ì‚¬ìš© ê·œì¹™:
- daily_routines[].exercises[] ë° suggested_exercises[] í•­ëª©ì„ ì‘ì„±í•  ë•ŒëŠ” ë°˜ë“œì‹œ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ì— ì œê³µëœ "[ì¶”ì²œ í›„ë³´ ìš´ë™ ë°ì´í„°(JSON)]" ë°°ì—´ì— ìˆëŠ” ìš´ë™ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
- ìœ„ ë°°ì—´ì— ì—†ëŠ” ìš´ë™ëª…, video_url, image_url ë“±ì„ ì ˆëŒ€ ì„ì˜ë¡œ ìƒì„±í•˜ê±°ë‚˜ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
- ê° ìš´ë™ì˜ ëª¨ë“  í•„ë“œ(exercise_id, video_url, video_length_seconds, title, standard_title, body_part, exercise_tool, description, muscles, target_group, fitness_factor_name, fitness_level_name ë“±)ëŠ” ë°˜ë“œì‹œ ì œê³µëœ JSON ë°°ì—´ì—ì„œ ê°€ì ¸ì˜¨ ê°’ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
- title í•„ë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš” (name í•„ë“œëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”). titleì€ í›„ë³´ ë°ì´í„°ì˜ title ê°’ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
- muscles í•„ë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš” (muscle_nameì´ ì•„ë‹™ë‹ˆë‹¤).
- video_urlê³¼ title/standard_titleì˜ ìŒì€ ì œê³µëœ JSONì—ì„œ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ê²ƒì„ ì‚¬ìš©í•˜ì„¸ìš”.
- í›„ë³´ ìš´ë™ ë°ì´í„°ë¥¼ ì°¸ê³ í•´ ë£¨í‹´ì„ êµ¬ì„±í•˜ê³ , ì„ íƒí•œ ì´ìœ ë¥¼ reference_videos/suggested_exercisesì— ëª…ì‹œí•˜ì„¸ìš”.
- next_target_musclesëŠ” ì œê³µëœ ê·¼ìœ¡ ë¼ë²¨ ëª©ë¡ì—ì„œë§Œ ì„ íƒí•˜ì„¸ìš”.
- JSON í˜•ì‹ì„ ì—„ê²©íˆ ì§€í‚¤ê³ , ëˆ„ë½ëœ í•„ë“œê°€ ì—†ë„ë¡ í•˜ì„¸ìš”.
- ë°˜ë“œì‹œ ìµœì†Œ 3ì¼(day 1 ì´ìƒ ì—°ì†) ì´ìƒì˜ daily_routinesë¥¼ ì‘ì„±í•˜ê³ , ê° dayë§ˆë‹¤ ìµœì†Œ 3ê°œ ì´ìƒì˜ ê°ê¸° ë‹¤ë¥¸ ìš´ë™ì„ í¬í•¨í•˜ì„¸ìš”.
- í•˜ë£¨ì— í•œ ê°€ì§€ ìš´ë™ë§Œ ì¶”ì²œí•˜ê±°ë‚˜ ë‹¨ì¼ ë³µê·¼ìš´ë™(ì˜ˆ: ì‹¯ì—… í•œ ê°€ì§€)ë§Œ ì œì‹œí•˜ì§€ ë§ê³ , ëŒ€ìƒ/ëª©ì /ìˆ˜ì¤€ì— ë§ëŠ” ë‹¤ì–‘í•œ ìš´ë™ ì¡°í•©ì„ êµ¬ì„±í•˜ì„¸ìš”."""
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.7,
                max_tokens=2000,
                response_format={"type": "json_object"}  # JSON í˜•ì‹ ê³ ì •
            )
            
            ai_routine = response.choices[0].message.content
            
            # JSON ì‘ë‹µ íŒŒì‹±
            try:
                parsed_routine = json.loads(ai_routine)
                
                # next_target_muscles ê²€ì¦ ë° ë§¤í•‘
                if "next_target_muscles" in parsed_routine:
                    original_muscles = parsed_routine["next_target_muscles"]
                    if isinstance(original_muscles, list):
                        validated_muscles = validate_and_map_muscles(original_muscles)
                        parsed_routine["next_target_muscles"] = validated_muscles
            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë¬¸ìì—´ ë°˜í™˜
                parsed_routine = {"raw_response": ai_routine}
            
            return {
                "success": True,
                "routine": parsed_routine,  # íŒŒì‹±ëœ JSON ë°˜í™˜
                "days": days,
                "frequency": frequency,
                "model": model,
                "rag_sources": rag_candidates
            }
            
        except Exception as e:
            return {
                "success": False,
                "message": f"ë£¨í‹´ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }

    def analyze_weekly_pattern_and_recommend(
        self,
        weekly_logs: List[Dict[str, Any]],
        model: str = "gpt-4o-mini",
        user_profile: Optional[Dict[str, str]] = None,
    ) -> Dict[str, Any]:
        """
        7ì¼ì¹˜ ìš´ë™ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ íŒ¨í„´ì„ ë¶„ì„í•˜ê³  ë§ì¶¤ ë£¨í‹´ì„ ì¶”ì²œí•©ë‹ˆë‹¤.

        Args:
            weekly_logs: ë‚ ì§œ ì—­ìˆœ ë˜ëŠ” ìˆœì°¨ ì •ë ¬ëœ 7ì¼ì¹˜ ìš´ë™ ê¸°ë¡ ë¦¬ìŠ¤íŠ¸
            model: ì‚¬ìš©í•  OpenAI ëª¨ë¸ (ê¸°ë³¸ê°’: "gpt-4o-mini")
            user_profile: ì‚¬ìš©ì í”„ë¡œí•„ ì •ë³´ (targetGroup, fitnessLevelName, fitnessFactorName)

        Returns:
            Dict[str, Any]: íŒ¨í„´ ë¶„ì„ ë° ë£¨í‹´ ì¶”ì²œ ê²°ê³¼
        """

        start_time = time.time()
        print(f"[ì£¼ê°„ íŒ¨í„´ ë¶„ì„] ì‹œì‘ - ëª¨ë¸: {model}, ë¡œê·¸ ìˆ˜: {len(weekly_logs)}")
        day_level_exercise_ids: List[int] = []
        rag_candidates: List[Dict[str, Any]] = []
        muscle_analysis: Optional[Dict[str, Any]] = None
        
        if not self.client:
            print("[ì£¼ê°„ íŒ¨í„´ ë¶„ì„] âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
            return {
                "success": False,
                "message": "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            }

        try:
            step_start = time.time()
            profile_data = self._clean_user_profile(user_profile)
            prompt, metrics = self._create_weekly_pattern_prompt(weekly_logs, profile_data)
            print(f"[ì£¼ê°„ íŒ¨í„´ ë¶„ì„] âœ… í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ ({time.time() - step_start:.2f}ì´ˆ)")
            
            if not self.exercise_rag:
                print(f"[ì£¼ê°„ íŒ¨í„´ ë¶„ì„] âš ï¸ RAG ì„œë¹„ìŠ¤ ì‚¬ìš© ë¶ˆê°€ (exercise_rag=None)")

            # 3ë‹¨ê³„: ì „ì²´ ë¶„ì„ ë° ë£¨í‹´ ì¶”ì²œ (RAG í›„ë³´ ì—†ì´)
            api_start = time.time()
            print(f"[ì£¼ê°„ íŒ¨í„´ ë¶„ì„] ğŸ¤– OpenAI API í˜¸ì¶œ ì‹œì‘ (ëª¨ë¸: {model})...")
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {
                        "role": "system",
                        "content": f"""ë‹¹ì‹ ì€ ì „ë¬¸ ìš´ë™ ì½”ì¹˜ì´ì ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:

{{
    "summary_metrics": {{
        "weekly_workout_count": 0,
        "rest_days": 0,
        "total_minutes": 0,
        "intensity_counts": {{"ìƒ": 0, "ì¤‘": 0, "í•˜": 0}},
        "body_part_counts": {{"ì–´ê¹¨": 0, "ê°€ìŠ´": 0}},
        "top_muscles": [{{"name": "ê·¼ìœ¡ëª…", "count": 0}}]
    }},
    "pattern_analysis": {{
        "consistency": "í›ˆë ¨ ë¹ˆë„ì™€ ê·œì¹™ì„± ë¶„ì„",
        "intensity_trend": "ê°•ë„ ë³€í™”ì™€ í”¼ë¡œ ëˆ„ì ì— ëŒ€í•œ í‰ê°€",
        "muscle_balance": {{
            "overworked": ["ê·¼ìœ¡ëª…1", "ê·¼ìœ¡ëª…2"],
            "underworked": ["ê·¼ìœ¡ëª…3", "ê·¼ìœ¡ëª…4"],
            "comments": "ê·¼ìœ¡ ì‚¬ìš© ê· í˜•ì— ëŒ€í•œ ì¢…í•© ì˜ê²¬"
        }},
        "habit_observation": "ìƒí™œ íŒ¨í„´ ë° íšŒë³µ ìŠµê´€ ê´€ë ¨ ì¸ì‚¬ì´íŠ¸",
        "exercise_diversity": {{
            "recent_exercises": ["ìµœê·¼ ìˆ˜í–‰í•œ ìš´ë™ëª…1", "ìµœê·¼ ìˆ˜í–‰í•œ ìš´ë™ëª…2"],
            "exercise_variety_score": "ìš´ë™ ë‹¤ì–‘ì„± ì ìˆ˜ (0-100)",
            "repetition_pattern": "ë°˜ë³µë˜ëŠ” ìš´ë™ íŒ¨í„´ ì„¤ëª…",
            "recommended_variation": "ìš´ë™ ë‹¤ì–‘ì„±ì„ ìœ„í•œ êµ¬ì²´ì ì¸ ì œì•ˆ",
            "preferred_equipment": ["ì‚¬ìš©ìê°€ ì„ í˜¸í•˜ëŠ” ìš´ë™ ë„êµ¬1", "ë„êµ¬2"],
            "equipment_usage_pattern": "ì‚¬ìš©ìê°€ ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” ìš´ë™ ë„êµ¬ íŒ¨í„´ ì„¤ëª…",
            "performance_analysis": {{
                "current_level": "ìš´ë™ ë©”ëª¨(ì¤‘ëŸ‰, ë°˜ë³µ, ì„¸íŠ¸)ë¥¼ ë¶„ì„í•œ í˜„ì¬ ìš´ë™ ìˆ˜ì¤€ í‰ê°€",
                "progression_trend": "ìš´ë™ ë©”ëª¨ë¥¼ í†µí•´ íŒŒì•…í•œ ì§„í–‰ ì¶”ì„¸ (í–¥ìƒ/ìœ ì§€/í•˜ë½)",
                "recommended_progression": "ìš´ë™ ë©”ëª¨ ê¸°ë°˜ ë‹¤ìŒ ë‹¨ê³„ ì¶”ì²œ (ì¤‘ëŸ‰ ì¦ê°€, ë°˜ë³µ ì¦ê°€, ì„¸íŠ¸ ì¦ê°€ ë“±)"
            }}
        }},
        "recovery_status": {{
            "fatigue_level": "í”¼ë¡œë„ ìˆ˜ì¤€ (ë‚®ìŒ/ë³´í†µ/ë†’ìŒ)",
            "recovery_needs": "íšŒë³µì´ í•„ìš”í•œ ë¶€ìœ„ë‚˜ ê·¼ìœ¡",
            "suggested_intensity": "ë‹¤ìŒ ì£¼ ê¶Œì¥ ê°•ë„ (ë‚®ìŒ/ë³´í†µ/ë†’ìŒ)"
        }}
    }},
    "recommended_routine": {{
        "weekly_overview": [
            "ìš”ì¼ë³„ ì£¼ìš” íƒ€ê²Ÿê³¼ ëª©í‘œ",
            "í•„ìš” ì‹œ íœ´ì‹/íšŒë³µ ê¶Œì¥"
        ],
        "daily_details": [
            {{
                "day": 1,
                "focus": "ì£¼ìš” ë¶€ìœ„ ë° ëª©í‘œ",
                "target_muscles": ["ê·¼ìœ¡ëª…1", "ê·¼ìœ¡ëª…2"],
                "rag_query": "ì´ ë‚ ì§œì— ì í•©í•œ ìš´ë™ì„ ê²€ìƒ‰í•˜ê¸° ìœ„í•œ RAG ì¿¼ë¦¬ (ì‚¬ìš©ì í”„ë¡œí•„, íƒ€ê²Ÿ ê·¼ìœ¡, ìš´ë™ ë‹¤ì–‘ì„±, íšŒë³µ ìƒíƒœë¥¼ ì¢…í•©í•œ ê²€ìƒ‰ì–´)",
                "exercises": [],
                "estimated_duration": "ì˜ˆìƒ ì†Œìš” ì‹œê°„"
            }}
        ],
        "progression_strategy": "ì ì§„ì  ê³¼ë¶€í•˜ ë˜ëŠ” ë³€í™”ë¥¼ ìœ„í•œ ì „ëµ"
    }},
    "recovery_guidance": "ì˜ì–‘, ìˆ˜ë©´, ìŠ¤íŠ¸ë ˆì¹­ ë“± íšŒë³µ íŒ",
    "next_target_muscles": ["ê·¼ìœ¡ëª…1", "ê·¼ìœ¡ëª…2", "ê·¼ìœ¡ëª…3"],
    "encouragement": "ê²©ë ¤ ë©”ì‹œì§€"
}}

ì¹œê·¼í•˜ê³  ê²©ë ¤í•˜ëŠ” í†¤ì„ ìœ ì§€í•˜ë©´ì„œ ë°˜ë“œì‹œ ìœ„ JSON êµ¬ì¡°ë¥¼ ë”°ë¥´ì„¸ìš”.

âš ï¸ ë§¤ìš° ì¤‘ìš” - ì‘ë‹µ ê¸¸ì´ ì œí•œ:
- ì „ì²´ ì‘ë‹µì€ ìµœëŒ€ 4000 í† í°(ì•½ 16000ì)ì„ ì´ˆê³¼í•˜ì§€ ë§ˆì„¸ìš”.
- ê° í…ìŠ¤íŠ¸ í•„ë“œëŠ” ì¶©ë¶„íˆ ìƒì„¸í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”:
  * "consistency": ìµœëŒ€ 300ì (í›ˆë ¨ ë¹ˆë„ì™€ ê·œì¹™ì„±ì— ëŒ€í•œ ìƒì„¸í•œ ë¶„ì„)
  * "intensity_trend": ìµœëŒ€ 300ì (ê°•ë„ ë³€í™”ì™€ í”¼ë¡œ ëˆ„ì ì— ëŒ€í•œ ìƒì„¸í•œ í‰ê°€)
  * "comments": ìµœëŒ€ 250ì (ê·¼ìœ¡ ì‚¬ìš© ê· í˜•ì— ëŒ€í•œ ì¢…í•© ì˜ê²¬)
  * "habit_observation": ìµœëŒ€ 250ì (ìƒí™œ íŒ¨í„´ ë° íšŒë³µ ìŠµê´€ ê´€ë ¨ ìƒì„¸í•œ ì¸ì‚¬ì´íŠ¸)
  * "focus": ê° dayë³„ ìµœëŒ€ 100ì (ì£¼ìš” ë¶€ìœ„ ë° ëª©í‘œì— ëŒ€í•œ ì„¤ëª…)
  * "notes": ê° ìš´ë™ë³„ ìµœëŒ€ 120ì (ìš´ë™ ìˆ˜í–‰ ì‹œ ì£¼ì˜ì‚¬í•­ì´ë‚˜ íŒ)
  * "progression_strategy": ìµœëŒ€ 300ì (ì ì§„ì  ê³¼ë¶€í•˜ ë˜ëŠ” ë³€í™”ë¥¼ ìœ„í•œ ìƒì„¸í•œ ì „ëµ)
  * "recovery_guidance": ìµœëŒ€ 300ì (ì˜ì–‘, ìˆ˜ë©´, ìŠ¤íŠ¸ë ˆì¹­ ë“± íšŒë³µ íŒì„ ìƒì„¸íˆ)
  * "encouragement": ìµœëŒ€ 250ì (ê²©ë ¤ ë©”ì‹œì§€)
  * "weekly_overview": ê° í•­ëª© ìµœëŒ€ 120ì (ìš”ì¼ë³„ ì£¼ìš” íƒ€ê²Ÿê³¼ ëª©í‘œë¥¼ ìƒì„¸íˆ)
  * "estimated_duration": "45ë¶„" í˜•ì‹ìœ¼ë¡œ ê°„ë‹¨íˆ
- ì¶©ë¶„íˆ ìƒì„¸í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ì„¤ëª…ì„ ì‘ì„±í•˜ë˜, ë¶ˆí•„ìš”í•œ ë°˜ë³µì€ í”¼í•˜ì„¸ìš”.
- JSONì´ ì™„ì „íˆ ë‹«íˆë„ë¡ ì£¼ì˜í•˜ì„¸ìš” (ëª¨ë“  ì¤‘ê´„í˜¸ì™€ ëŒ€ê´„í˜¸ê°€ ì˜¬ë°”ë¥´ê²Œ ë‹«í˜€ì•¼ í•¨).

âš ï¸ ì¤‘ìš”: next_target_muscles, muscle_balance.overworked, muscle_balance.underworked í•„ë“œëŠ” ë°˜ë“œì‹œ ì•„ë˜ ê·¼ìœ¡ ë¼ë²¨ ëª©ë¡ì— ì •í™•íˆ í¬í•¨ëœ ì´ë¦„ë§Œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
ë‹¤ë¥¸ ì´ë¦„(ì˜ˆ: "ì–´ê¹¨ê·¼ìœ¡", "íŒ”ê·¼ìœ¡", "ë³µê·¼" ë“±)ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
ë°˜ë“œì‹œ ì•„ë˜ ëª©ë¡ì—ì„œ ì •í™•í•œ ê·¼ìœ¡ëª…ì„ ì„ íƒí•˜ì„¸ìš”.

âš ï¸ ë§¤ìš° ì¤‘ìš” - ë£¨í‹´ ë¶„ëŸ‰ ì¡°ê±´:
- ë°˜ë“œì‹œ ìµœì†Œ 3ì¼ ì´ìƒì˜ daily_detailsë¥¼ ì‘ì„±í•˜ì„¸ìš”.
- daily_details[].target_muscles í•„ë“œëŠ” MUSCLE_LABELSì— í¬í•¨ëœ ëª…ì¹­ 2~4ê°œë¡œ ì‘ì„±í•˜ì„¸ìš”.
- daily_details[].exercises[] í•„ë“œëŠ” ë¹ˆ ë°°ì—´ë¡œ ë‘ì„¸ìš”. ì´í›„ ì‹œìŠ¤í…œì´ RAG ê²€ìƒ‰ ê²°ê³¼ë¡œ ì±„ì›ë‹ˆë‹¤.
- ê° dayì˜ focusì™€ estimated_durationì€ ì‘ì„±í•˜ë˜, êµ¬ì²´ì ì¸ ìš´ë™ ëª©ë¡ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

âš ï¸ ë§¤ìš° ì¤‘ìš” - RAG ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±:
- daily_details[].rag_query í•„ë“œì— ê° ë‚ ì§œì— ì í•©í•œ ìš´ë™ì„ ê²€ìƒ‰í•˜ê¸° ìœ„í•œ ì¿¼ë¦¬ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
- ì¿¼ë¦¬ëŠ” ë‹¤ìŒ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”:
  1. ì‚¬ìš©ì í”„ë¡œí•„ ì •ë³´ (ëŒ€ìƒ ì—°ë ¹ëŒ€, ìš´ë™ ìˆ˜ì¤€, ìš´ë™ ëª©ì )
  2. í•´ë‹¹ ë‚ ì§œì˜ target_muscles (íƒ€ê²Ÿ ê·¼ìœ¡ëª…)
  3. pattern_analysis.exercise_diversity.recommended_variation (ìš´ë™ ë‹¤ì–‘ì„± ì œì•ˆ)
  4. pattern_analysis.exercise_diversity.preferred_equipment (ì‚¬ìš©ìê°€ ì„ í˜¸í•˜ëŠ” ìš´ë™ ë„êµ¬ - ë§¤ìš° ì¤‘ìš”!)
  5. pattern_analysis.exercise_diversity.equipment_usage_pattern (ìš´ë™ ë„êµ¬ ì‚¬ìš© íŒ¨í„´)
  6. pattern_analysis.exercise_diversity.performance_analysis (ìš´ë™ ìˆ˜í–‰ ìˆ˜ì¤€ ë¶„ì„ - ì¤‘ëŸ‰, ë°˜ë³µ, ì„¸íŠ¸ ì •ë³´ ë°˜ì˜)
  7. pattern_analysis.recovery_status (íšŒë³µ ìƒíƒœ ë° ê¶Œì¥ ê°•ë„)
  8. pattern_analysis.muscle_balance (ë¶€ì¡±í•œ ê·¼ìœ¡/ê³¼ì‚¬ìš© ê·¼ìœ¡ ì •ë³´)
- âš ï¸ ë§¤ìš° ì¤‘ìš”: ì‚¬ìš©ìê°€ ì£¼ê°„ ì¼ì§€ì—ì„œ ì£¼ë¡œ ì‚¬ìš©í•œ ìš´ë™ ë„êµ¬(ë¨¸ì‹ , ë¤ë²¨, ë°”ë²¨, ì¼€ì´ë¸”, ê¸°êµ¬ ë“±)ë¥¼ ë°˜ë“œì‹œ ì¿¼ë¦¬ì— í¬í•¨í•˜ì„¸ìš”.
- ì‚¬ìš©ìê°€ ë¨¸ì‹ ì´ë‚˜ ê¸°êµ¬ë¥¼ ì‚¬ìš©í–ˆë‹¤ë©´ "ë¨¸ì‹ ", "ê¸°êµ¬", "ë¤ë²¨" ë“±ì˜ í‚¤ì›Œë“œë¥¼ ì¿¼ë¦¬ì— í¬í•¨í•˜ì„¸ìš”.
- ì²´ì¤‘ ìš´ë™ë§Œ ì‚¬ìš©í–ˆë‹¤ë©´ "ì²´ì¤‘" í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ë˜, ì‚¬ìš©ìê°€ ê¸°êµ¬ë¥¼ ì‚¬ìš©í–ˆë‹¤ë©´ ê¸°êµ¬ ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ìš°ì„ í•˜ì„¸ìš”.
- âš ï¸ ìš´ë™ ìˆ˜í–‰ ìˆ˜ì¤€ ë°˜ì˜: performance_analysisì˜ current_levelê³¼ recommended_progressionì„ ê³ ë ¤í•˜ì—¬ ì ì ˆí•œ ë‚œì´ë„ì™€ ê°•ë„ì˜ ìš´ë™ì„ ê²€ìƒ‰í•˜ë„ë¡ ì¿¼ë¦¬ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
- ì¿¼ë¦¬ëŠ” ìì—°ì–´ë¡œ ì‘ì„±í•˜ë˜, í•µì‹¬ í‚¤ì›Œë“œ(ê·¼ìœ¡ëª…, ìš´ë™ ëª©ì , ê°•ë„, ìš´ë™ ë„êµ¬ ë“±)ë¥¼ í¬í•¨í•˜ì„¸ìš”.
- ì˜ˆì‹œ: "ì„±ì¸ ì¤‘ê¸‰ ê·¼ë ¥ ë¨¸ì‹  í°ê°€ìŠ´ê·¼ ê°•í™” ìš´ë™" ë˜ëŠ” "ë¤ë²¨ ê¸°êµ¬ ìœ„íŒ”ì„¸ê°ˆë˜ê·¼ ìš´ë™" ë˜ëŠ” "ì¼€ì´ë¸” ì–´ê¹¨ì„¸ëª¨ê·¼ ìš´ë™"
- ì¿¼ë¦¬ ê¸¸ì´ëŠ” 10-50ì ì •ë„ë¡œ ì ì ˆí•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
- MUSCLE_LABELSì— í¬í•¨ëœ ì •í™•í•œ ê·¼ìœ¡ëª…ì„ ì‚¬ìš©í•˜ì„¸ìš”.

âš ï¸ ë§¤ìš° ì¤‘ìš” - ìš´ë™ ë‹¤ì–‘ì„± ë¶„ì„:
- pattern_analysis.exercise_diversity.recent_exercisesì—ëŠ” ìµœê·¼ 7ì¼ê°„ ìˆ˜í–‰í•œ ëª¨ë“  ìš´ë™ëª…ì„ ì •í™•íˆ ë‚˜ì—´í•˜ì„¸ìš”.
- ìš´ë™ëª…ì€ ì •í™•í•œ ì œëª©(title)ì„ ì‚¬ìš©í•˜ì„¸ìš” (ì˜ˆ: "í‘¸ì‹œì—…", "íŠ¸ë¼ì´ì…‰ìŠ¤ ë”¥", "ëŸ°ì§€ ìœ„ë“œ ë ˆì´ì¦ˆ").
- exercise_variety_scoreëŠ” ìš´ë™ ë‹¤ì–‘ì„±ì„ 0-100 ì ìˆ˜ë¡œ í‰ê°€í•˜ì„¸ìš” (ê°™ì€ ìš´ë™ ë°˜ë³µì´ ë§ìœ¼ë©´ ë‚®ì€ ì ìˆ˜).
- repetition_patternì—ëŠ” ë°˜ë³µë˜ëŠ” ìš´ë™ íŒ¨í„´ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
- recommended_variationì—ëŠ” ìš´ë™ ë‹¤ì–‘ì„±ì„ ë†’ì´ê¸° ìœ„í•œ êµ¬ì²´ì ì¸ ì œì•ˆì„ ì‘ì„±í•˜ì„¸ìš”.
- pattern_analysis.exercise_diversity.preferred_equipmentì—ëŠ” ì‚¬ìš©ìê°€ ì£¼ê°„ ì¼ì§€ì—ì„œ ì£¼ë¡œ ì‚¬ìš©í•œ ìš´ë™ ë„êµ¬ë¥¼ ë‚˜ì—´í•˜ì„¸ìš” (ì˜ˆ: "ë¨¸ì‹ ", "ë¤ë²¨", "ë°”ë²¨", "ì¼€ì´ë¸”", "ê¸°êµ¬" ë“±).
- pattern_analysis.exercise_diversity.equipment_usage_patternì—ëŠ” ì‚¬ìš©ìì˜ ìš´ë™ ë„êµ¬ ì‚¬ìš© íŒ¨í„´ì„ ì„¤ëª…í•˜ì„¸ìš” (ì˜ˆ: "ì£¼ë¡œ ë¨¸ì‹ ê³¼ ê¸°êµ¬ë¥¼ ì‚¬ìš©", "ì²´ì¤‘ ìš´ë™ ìœ„ì£¼" ë“±).
- âš ï¸ ë§¤ìš° ì¤‘ìš” - ìš´ë™ ìˆ˜í–‰ ìˆ˜ì¤€ ë¶„ì„ (performance_analysis):
  * pattern_analysis.exercise_diversity.performance_analysis.current_level: ìš´ë™ ë©”ëª¨(exerciseMemo)ì— ê¸°ë¡ëœ ì¤‘ëŸ‰, ë°˜ë³µ íšŸìˆ˜, ì„¸íŠ¸ ìˆ˜, ì‹œê°„ ë“±ì„ ì¢…í•© ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì˜ í˜„ì¬ ìš´ë™ ìˆ˜ì¤€ì„ í‰ê°€í•˜ì„¸ìš” (ì˜ˆ: "ì¤‘ê¸‰ ìˆ˜ì¤€, ë²¤ì¹˜í”„ë ˆìŠ¤ 60kg 3ì„¸íŠ¸ 10íšŒ ìˆ˜í–‰")
  * pattern_analysis.exercise_diversity.performance_analysis.progression_trend: ìš´ë™ ë©”ëª¨ë¥¼ í†µí•´ íŒŒì•…í•œ ì§„í–‰ ì¶”ì„¸ë¥¼ ë¶„ì„í•˜ì„¸ìš” (í–¥ìƒ/ìœ ì§€/í•˜ë½, ì¤‘ëŸ‰ì´ë‚˜ ë°˜ë³µì´ ì¦ê°€í–ˆëŠ”ì§€ ë“±)
  * pattern_analysis.exercise_diversity.performance_analysis.recommended_progression: ìš´ë™ ë©”ëª¨ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ ë‹¨ê³„ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì¶”ì²œí•˜ì„¸ìš” (ì˜ˆ: "ì¤‘ëŸ‰ 5kg ì¦ê°€", "ë°˜ë³µ íšŸìˆ˜ 2íšŒ ì¦ê°€", "ì„¸íŠ¸ 1ê°œ ì¶”ê°€" ë“±)

âš ï¸ ë§¤ìš° ì¤‘ìš” - íšŒë³µ ìƒíƒœ ë¶„ì„:
- recovery_status.fatigue_levelì€ ì£¼ê°„ ìš´ë™ ê°•ë„ì™€ ë¹ˆë„ë¥¼ ì¢…í•©í•˜ì—¬ í‰ê°€í•˜ì„¸ìš”.
- recovery_status.recovery_needsì—ëŠ” íšŒë³µì´ í•„ìš”í•œ ë¶€ìœ„ë‚˜ ê·¼ìœ¡ì„ êµ¬ì²´ì ìœ¼ë¡œ ë‚˜ì—´í•˜ì„¸ìš”.
- recovery_status.suggested_intensityëŠ” ë‹¤ìŒ ì£¼ ê¶Œì¥ ê°•ë„ë¥¼ ì œì‹œí•˜ì„¸ìš”."""
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.7,
                max_tokens=4000,  # í”„ë¡¬í”„íŠ¸ì—ì„œ ëª…ì‹œí•œ ìµœëŒ€ í† í° ìˆ˜ì™€ ì¼ì¹˜
                response_format={"type": "json_object"}
            )
            api_elapsed = time.time() - api_start
            print(f"[ì£¼ê°„ íŒ¨í„´ ë¶„ì„] âœ… OpenAI API ì‘ë‹µ ìˆ˜ì‹  ({api_elapsed:.2f}ì´ˆ)")

            if not response or not response.choices:
                print(f"[ì£¼ê°„ íŒ¨í„´ ë¶„ì„] âŒ OpenAI API ì‘ë‹µì´ ë¹„ì–´ìˆìŒ")
                raise Exception("OpenAI API ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

            ai_response = response.choices[0].message.content
            if not ai_response:
                print(f"[ì£¼ê°„ íŒ¨í„´ ë¶„ì„] âŒ AI ì‘ë‹µ ë‚´ìš©ì´ ë¹„ì–´ìˆìŒ")
                raise Exception("AI ì‘ë‹µ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

            print(f"[ì£¼ê°„ íŒ¨í„´ ë¶„ì„] ğŸ“„ AI ì‘ë‹µ ê¸¸ì´: {len(ai_response)} ë¬¸ì")

            parse_start = time.time()
            try:
                parsed_response = json.loads(ai_response)
                parse_elapsed = time.time() - parse_start
                print(f"[ì£¼ê°„ íŒ¨í„´ ë¶„ì„] âœ… JSON íŒŒì‹± ì™„ë£Œ ({parse_elapsed:.2f}ì´ˆ)")

                for key in [
                    ("next_target_muscles", parsed_response.get("next_target_muscles")),
                    ("overworked", parsed_response.get("pattern_analysis", {})
                                 .get("muscle_balance", {})
                                 .get("overworked")),
                    ("underworked", parsed_response.get("pattern_analysis", {})
                                 .get("muscle_balance", {})
                                 .get("underworked"))
                ]:
                    field_name, muscles = key
                    if isinstance(muscles, list):
                        validated = validate_and_map_muscles(muscles)

                        if field_name == "next_target_muscles":
                            parsed_response["next_target_muscles"] = validated
                            # next_target ê·¼ìœ¡ì— ë§ëŠ” RAG ìš´ë™ ì¶”ê°€
                            if validated and self.exercise_rag:
                                try:
                                    next_target_exercises = self._search_exercises_for_muscles(
                                        validated,
                                        profile_data,
                                        per_muscle=3,
                                    )
                                    if next_target_exercises:
                                        parsed_response["next_target_exercises"] = next_target_exercises
                                        print(f"[ì£¼ê°„ íŒ¨í„´ ë¶„ì„] âœ… next_target_exercises ìƒì„± ì™„ë£Œ: {len(next_target_exercises)}ê°œ ê·¼ìœ¡ë³„ ìš´ë™")
                                except Exception as e:
                                    print(f"[ì£¼ê°„ íŒ¨í„´ ë¶„ì„] âš ï¸ next_target_exercises ìƒì„± ì‹¤íŒ¨: {str(e)}")
                        else:
                            muscle_balance = parsed_response.setdefault("pattern_analysis", {}).setdefault("muscle_balance", {})
                            muscle_balance[field_name] = validated
                
                # ë£¨í‹´ ê²€ì¦ (exercisesëŠ” í›„ì²˜ë¦¬ RAG ê²°ê³¼ë¡œ ì±„ì›€)
                recommended_routine = parsed_response.get("recommended_routine", {})
                daily_details = recommended_routine.get("daily_details", [])
                print(f"[ì£¼ê°„ íŒ¨í„´ ë¶„ì„] ğŸ“Š ì¶”ì²œ ë£¨í‹´: {len(daily_details)}ì¼")
                
                # exercises í•„ë“œëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë¹ˆ ë°°ì—´ë¡œ ì„¤ì •
                for day in daily_details:
                    if not isinstance(day, dict):
                        continue
                    # exercises í•„ë“œê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ ë¹ˆ ë°°ì—´ë¡œ ì„¤ì •
                    if "exercises" not in day or not day.get("exercises"):
                        day["exercises"] = []

                day_level_exercise_ids = []
                if daily_details:
                    # LLM ë¶„ì„ ê²°ê³¼ì—ì„œ ìš´ë™ ë‹¤ì–‘ì„± ì •ë³´ ì¶”ì¶œ (ìš´ë™ ë„êµ¬ ì •ë³´ í¬í•¨)
                    pattern_analysis = parsed_response.get("pattern_analysis", {})
                    exercise_diversity = pattern_analysis.get("exercise_diversity", {})
                    
                    (
                        day_level_exercise_ids,
                        rag_candidates,
                    ) = self._populate_daily_details_with_exercises(
                        daily_details,
                        profile_data,
                        fallback_muscles=parsed_response.get("next_target_muscles"),
                        exercise_diversity=exercise_diversity,
                    )

                muscle_analysis = self._build_muscle_analysis_from_response(parsed_response)
                
            except json.JSONDecodeError as json_err:
                parse_elapsed = time.time() - parse_start
                print(f"[ì£¼ê°„ íŒ¨í„´ ë¶„ì„] âŒ JSON íŒŒì‹± ì‹¤íŒ¨ ({parse_elapsed:.2f}ì´ˆ): {str(json_err)}")
                print(f"[ì£¼ê°„ íŒ¨í„´ ë¶„ì„] ğŸ“„ ì‘ë‹µ ì¼ë¶€ (ì²˜ìŒ 500ì): {ai_response[:500]}...")
                print(f"[ì£¼ê°„ íŒ¨í„´ ë¶„ì„] ğŸ“„ ì‘ë‹µ ì¼ë¶€ (ë 500ì): ...{ai_response[-500:]}")
                
                # JSON ë³µêµ¬ ì‹œë„
                try:
                    parsed_response = self._repair_json_response(ai_response, json_err)
                    if parsed_response:
                        print(f"[ì£¼ê°„ íŒ¨í„´ ë¶„ì„] âš ï¸ JSON ë³µêµ¬ ì„±ê³µ (ë¶€ë¶„ íŒŒì‹±)")
                    else:
                        parsed_response = {"raw_response": ai_response, "parse_error": str(json_err)}
                except Exception as repair_err:
                    print(f"[ì£¼ê°„ íŒ¨í„´ ë¶„ì„] âŒ JSON ë³µêµ¬ ì‹¤íŒ¨: {str(repair_err)}")
                    parsed_response = {"raw_response": ai_response, "parse_error": str(json_err)}

            total_elapsed = time.time() - start_time
            print(f"[ì£¼ê°„ íŒ¨í„´ ë¶„ì„] âœ… ì™„ë£Œ - ì´ ì†Œìš” ì‹œê°„: {total_elapsed:.2f}ì´ˆ")
            
            # RAG ê²€ìƒ‰ ê²°ê³¼ë¥¼ exercise_idë§Œ ì¶”ì¶œ
            recommended_exercise_ids: List[int] = []
            if rag_candidates:
                for candidate in rag_candidates:
                    meta = candidate.get("metadata", {}) or {}
                    exercise_id = meta.get("exercise_id")
                    if exercise_id is not None:
                        try:
                            recommended_exercise_ids.append(int(exercise_id))
                        except (TypeError, ValueError):
                            continue

            if day_level_exercise_ids:
                recommended_exercise_ids.extend(day_level_exercise_ids)

            if recommended_exercise_ids:
                deduped_ids: List[int] = []
                seen_ids: Set[int] = set()
                for ex_id in recommended_exercise_ids:
                    if not isinstance(ex_id, int):
                        continue
                    if ex_id in seen_ids:
                        continue
                    seen_ids.add(ex_id)
                    deduped_ids.append(ex_id)
                recommended_exercise_ids = deduped_ids
            
            return {
                "success": True,
                "result": parsed_response,
                "metrics_summary": metrics,
                "rag_sources": rag_candidates,  # ì›ë³¸ RAG ê²°ê³¼ (ì „ì²´ ì •ë³´ í¬í•¨, í•˜ìœ„ í˜¸í™˜ì„±)
                "recommended_exercises": recommended_exercise_ids,  # RAG ê²€ìƒ‰ ê²°ê³¼ (exercise_idë§Œ)
                "muscle_analysis": muscle_analysis,  # LLM ê·¼ìœ¡ ë¶„ì„ ê²°ê³¼
                "model": model
            }

        except Exception as e:
            total_elapsed = time.time() - start_time
            print(f"[ì£¼ê°„ íŒ¨í„´ ë¶„ì„] âŒ ì˜¤ë¥˜ ë°œìƒ (ì´ {total_elapsed:.2f}ì´ˆ): {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                "success": False,
                "message": f"ì£¼ê°„ íŒ¨í„´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }
    
    def _create_log_analysis_prompt(
        self,
        workout_log: Dict[str, Any],
        user_profile: Optional[Dict[str, str]] = None,
    ) -> str:
        """ìš´ë™ ì¼ì§€ ë°ì´í„°ë¥¼ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜"""
        
        date = workout_log.get("date", "ë‚ ì§œ ì •ë³´ ì—†ìŒ")
        memo = workout_log.get("memo", "")
        exercises = workout_log.get("exercises", [])
        profile_block = self._format_user_profile_block(user_profile or {})
        
        prompt = f"""
ì‚¬ìš©ìì˜ ìš´ë™ ì¼ì§€ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

[ì‚¬ìš©ì í”„ë¡œí•„]
{profile_block}

[ìš´ë™ ì¼ì§€ ì •ë³´]
ë‚ ì§œ: {date}
ë©”ëª¨: {memo}

[ìš´ë™ ìƒì„¸]
"""
        
        for i, ex_data in enumerate(exercises, 1):
            exercise = ex_data.get("exercise", {})
            muscles_list = exercise.get('muscles', [])
            muscles_text = ', '.join(muscles_list) if muscles_list else 'ì •ë³´ ì—†ìŒ'
            prompt += f"""
ìš´ë™ {i}:
- ìš´ë™ëª…: {exercise.get('title', 'N/A')}
- ê·¼ìœ¡ ë¶€ìœ„: {muscles_text}
- ê°•ë„: {ex_data.get('intensity', 'N/A')}
- ìš´ë™ ì‹œê°„: {ex_data.get('exerciseTime', 0)}ë¶„
- ìš´ë™ ë„êµ¬: {exercise.get('exerciseTool', 'N/A')}
"""
        
        prompt += """

ìœ„ ìš´ë™ ì¼ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ í¬í•¨í•œ ìƒì„¸ í‰ê°€ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:
1. ì „ë°˜ì ì¸ ìš´ë™ í‰ê°€ (ê°•ë„, ì‹œê°„, ë‹¤ì–‘í•œì„±)
2. íƒ€ê²Ÿ ê·¼ìœ¡ ë¶„ì„ ë° íš¨ê³¼
3. ì¢‹ì€ ì ê³¼ ê°œì„ í•  ì 
4. ë‹¤ìŒ ìš´ë™ì„ ìœ„í•œ êµ¬ì²´ì ì¸ ì¶”ì²œ
5. ë¶€ìƒ ì˜ˆë°©ì„ ìœ„í•œ ì£¼ì˜ì‚¬í•­
6. ì‚¬ìš©ì í”„ë¡œí•„(targetGroup, fitnessLevelName, fitnessFactorName)ì´ ì œê³µë˜ë©´ í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ìš´ë™ ê°•ë„ì™€ ëª©ì ë§Œ ì¶”ì²œí•˜ê³ , ì œê³µë˜ì§€ ì•Šìœ¼ë©´ ì¼ë°˜ì ì¸ ì•ˆì „ ê¸°ì¤€ì„ ë”°ë¥´ì„¸ìš”.

[ê·¼ìœ¡ ë¼ë²¨ ëª©ë¡]
ì•„ë˜ ëª©ë¡ì— í¬í•¨ëœ ê·¼ìœ¡ëª…ë§Œ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ ìš´ë™ì„ ì¶”ì²œí•  ê·¼ìœ¡(next_target_muscles)ì„ 2~5ê°œ ì„ ì •í•˜ì„¸ìš”.
ì„ ì • ê¸°ì¤€: (1) ìµœê·¼ ê¸°ë¡ì—ì„œ ë¶€ì¡±í•˜ê±°ë‚˜ ëœ ì‚¬ìš©ëœ ê·¼ìœ¡, (2) ê³¼ì‚¬ìš© ë¶€ìœ„ëŠ” í”¼í•¨, (3) ì „ì‹  ê· í˜• ê°œì„ .
{', '.join(MUSCLE_LABELS)}

ì¹œê·¼í•˜ê³  ê²©ë ¤í•˜ëŠ” í†¤ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""
        
        return prompt

    def _search_exercises_for_muscles(
        self,
        muscles: List[str],
        profile_data: Optional[Dict[str, str]] = None,
        per_muscle: int = 3,
    ) -> Dict[str, List[int]]:
        """next_target_musclesì— ë§ëŠ” ìš´ë™ì„ RAGë¡œ ê²€ìƒ‰"""
        if not self.exercise_rag or not muscles:
            return {}

        filters = self._build_rag_filter_options(profile_data)
        muscle_exercises: Dict[str, List[int]] = {}

        for muscle in muscles:
            query = f"{muscle} ê°•í™” ìš´ë™"
            alias_tokens = self._expand_muscle_aliases(muscle)
            try:
                rag_results = self.exercise_rag.search(
                    query,
                    top_k=per_muscle,
                    target_group_filter=filters["target_group_filter"],
                    exclude_target_groups=filters["exclude_target_groups"],
                    fitness_factor_filter=filters["fitness_factor_filter"],
                    exclude_fitness_factors=filters["exclude_fitness_factors"],
                )
            except Exception as exc:
                print(f"[RAG] âš ï¸ '{muscle}' ê²€ìƒ‰ ì‹¤íŒ¨: {exc}")
                continue

            exercise_ids: List[int] = []
            for item in rag_results:
                meta = item.get("metadata") or {}
                ex_id = meta.get("exercise_id")
                if ex_id is None:
                    continue

                if not self._metadata_matches_muscle(meta.get("muscles"), alias_tokens):
                    continue

                try:
                    exercise_ids.append(int(ex_id))
                except (TypeError, ValueError):
                    continue

                if len(exercise_ids) >= per_muscle:
                    break

            if exercise_ids:
                muscle_exercises[muscle] = exercise_ids

        return muscle_exercises

    def _format_rag_exercise_payload(
        self,
        metadata: Dict[str, Any],
        score: Optional[float] = None,
    ) -> Dict[str, Any]:
        """RAG ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë£¨í‹´ì—ì„œ ì‚¬ìš©í•  í˜•íƒœë¡œ ì •ê·œí™”"""
        return {
            "exercise_id": metadata.get("exercise_id"),
            "title": metadata.get("title"),
            "standard_title": metadata.get("standard_title"),
            "training_name": metadata.get("training_name"),
            "body_part": metadata.get("body_part"),
            "exercise_tool": metadata.get("exercise_tool"),
            "fitness_factor_name": metadata.get("fitness_factor_name"),
            "fitness_level_name": metadata.get("fitness_level_name"),
            "target_group": metadata.get("target_group"),
            "training_aim_name": metadata.get("training_aim_name"),
            "training_place_name": metadata.get("training_place_name"),
            "training_section_name": metadata.get("training_section_name"),
            "training_step_name": metadata.get("training_step_name"),
            "description": metadata.get("description"),
            "muscles": metadata.get("muscles"),
            "video_url": metadata.get("video_url"),
            "video_length_seconds": metadata.get("video_length_seconds"),
            "image_url": metadata.get("image_url"),
            "image_file_name": metadata.get("image_file_name"),
            "score": score,
        }

    def _search_day_exercises_with_rag(
        self,
        target_muscles: List[str],
        profile_data: Optional[Dict[str, str]] = None,
        per_day: int = 4,
        exercise_diversity: Optional[Dict[str, Any]] = None,
        recovery_status: Optional[Dict[str, Any]] = None,
        underworked_muscles: Optional[List[str]] = None,
        overworked_muscles: Optional[List[str]] = None,
    ) -> List[Dict[str, Any]]:
        """ë£¨í‹´ ì¼ìë³„ íƒ€ê²Ÿ ê·¼ìœ¡ì„ ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì œ ìš´ë™ ë©”íƒ€ë°ì´í„°ë¥¼ ê²€ìƒ‰"""
        if not self.exercise_rag or not target_muscles:
            return []

        filters = self._build_rag_filter_options(profile_data)
        profile_prefix = self._build_profile_prefix(profile_data)
        seen_ids: Set[int] = set()
        day_exercises: List[Dict[str, Any]] = []

        for muscle in target_muscles:
            alias_tokens = self._expand_muscle_aliases(muscle)
            
            # RAG ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±: ì‚¬ìš©ì ì •ë³´ + ì£¼ê°„ ë¶„ì„ ê²°ê³¼ ê²°í•©
            query = self._build_enhanced_rag_query(
                muscle=muscle,
                profile_prefix=profile_prefix,
                exercise_diversity=exercise_diversity,
                recovery_status=recovery_status,
                target_muscles=target_muscles,
                underworked_muscles=underworked_muscles,
                overworked_muscles=overworked_muscles,
            )
            
            try:
                top_k = 8  # ì¶©ë¶„í•œ í›„ë³´ í™•ë³´
                rag_results = self.exercise_rag.search(
                    query,
                    top_k=top_k,
                    target_group_filter=filters["target_group_filter"],
                    exclude_target_groups=filters["exclude_target_groups"],
                    fitness_factor_filter=filters["fitness_factor_filter"],
                    exclude_fitness_factors=filters["exclude_fitness_factors"],
                )
            except Exception as exc:
                print(f"[ì£¼ê°„ íŒ¨í„´ ë¶„ì„] âš ï¸ Day RAG ê²€ìƒ‰ ì‹¤íŒ¨ (muscle={muscle}): {exc}")
                continue

            for item in rag_results:
                meta = item.get("metadata") or {}
                exercise_id = meta.get("exercise_id")
                if exercise_id is None:
                    continue

                try:
                    normalized_id = int(exercise_id)
                except (TypeError, ValueError):
                    continue

                if normalized_id in seen_ids:
                    continue

                if not self._metadata_matches_muscle(meta.get("muscles"), alias_tokens):
                    continue

                normalized_meta = dict(meta)
                normalized_meta["exercise_id"] = normalized_id

                formatted = self._format_rag_exercise_payload(
                    normalized_meta,
                    score=item.get("score"),
                )
                day_exercises.append(formatted)
                seen_ids.add(normalized_id)

                if len(day_exercises) >= per_day:
                    break

            if len(day_exercises) >= per_day:
                break

        return day_exercises

    def _validate_rag_query(
        self,
        query: Optional[str],
        target_muscles: List[str],
        profile_data: Optional[Dict[str, str]] = None,
        exercise_diversity: Optional[Dict[str, Any]] = None,
    ) -> Tuple[bool, str]:
        """
        LLMì´ ìƒì„±í•œ RAG ì¿¼ë¦¬ë¥¼ ê²€ì¦í•˜ê³  ê°œì„ í•©ë‹ˆë‹¤.
        
        Args:
            query: ê²€ì¦í•  ì¿¼ë¦¬ ë¬¸ìì—´
            target_muscles: íƒ€ê²Ÿ ê·¼ìœ¡ ëª©ë¡
            profile_data: ì‚¬ìš©ì í”„ë¡œí•„ ë°ì´í„°
            exercise_diversity: ìš´ë™ ë‹¤ì–‘ì„± ë¶„ì„ ê²°ê³¼ (ìš´ë™ ë„êµ¬ ì •ë³´ í¬í•¨)
            
        Returns:
            (is_valid, validated_query) íŠœí”Œ
            - is_valid: ì¿¼ë¦¬ê°€ ìœ íš¨í•œì§€ ì—¬ë¶€
            - validated_query: ê²€ì¦/ìˆ˜ì •ëœ ì¿¼ë¦¬
        """
        if not query or not isinstance(query, str):
            return False, ""
        
        query = query.strip()
        
        # 1. ê¸¸ì´ ê²€ì¦ (ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸¸ë©´ ìˆ˜ì •)
        if len(query) < 3:
            return False, ""
        if len(query) > 200:
            query = query[:200].strip()
            print(f"[RAG ì¿¼ë¦¬ ê²€ì¦] âš ï¸ ì¿¼ë¦¬ê°€ ë„ˆë¬´ ê¸¸ì–´ì„œ ì˜ëìŠµë‹ˆë‹¤: {len(query)}ì")
        
        query_lower = query.lower()
        
        # 2. íƒ€ê²Ÿ ê·¼ìœ¡ëª…ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        has_target_muscle = False
        for muscle in target_muscles:
            if muscle.lower() in query_lower:
                has_target_muscle = True
                break
        
        # íƒ€ê²Ÿ ê·¼ìœ¡ì´ ì—†ìœ¼ë©´ ì¶”ê°€
        if not has_target_muscle and target_muscles:
            primary_muscle = target_muscles[0]
            query = f"{query} {primary_muscle}".strip()
            print(f"[RAG ì¿¼ë¦¬ ê²€ì¦] âš ï¸ íƒ€ê²Ÿ ê·¼ìœ¡ëª…ì´ ì—†ì–´ì„œ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤: {primary_muscle}")
            query_lower = query.lower()
        
        # 3. ìš´ë™ ë„êµ¬ ì •ë³´ í™•ì¸ ë° ì¶”ê°€ (ë§¤ìš° ì¤‘ìš”!)
        if exercise_diversity:
            preferred_equipment = exercise_diversity.get("preferred_equipment", [])
            if preferred_equipment and isinstance(preferred_equipment, list):
                # ì¿¼ë¦¬ì— ìš´ë™ ë„êµ¬ í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
                equipment_keywords = ["ë¨¸ì‹ ", "ê¸°êµ¬", "ë¤ë²¨", "ë°”ë²¨", "ì¼€ì´ë¸”", "ìŠ¤ë¯¸ìŠ¤", "ë ˆê·¸", "í”„ë ˆìŠ¤", "ì²´ì¤‘", "ë§¤íŠ¸"]
                has_equipment = any(keyword in query_lower for keyword in equipment_keywords)
                
                if not has_equipment and preferred_equipment:
                    # ì‚¬ìš©ìê°€ ì„ í˜¸í•˜ëŠ” ìš´ë™ ë„êµ¬ë¥¼ ì¿¼ë¦¬ì— ì¶”ê°€
                    # ê°€ì¥ ë§ì´ ì‚¬ìš©í•œ ë„êµ¬ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì¶”ê°€
                    primary_equipment = preferred_equipment[0] if preferred_equipment else ""
                    if primary_equipment:
                        query = f"{query} {primary_equipment}".strip()
                        print(f"[RAG ì¿¼ë¦¬ ê²€ì¦] âœ… ìš´ë™ ë„êµ¬ ì •ë³´ ì¶”ê°€: {primary_equipment}")
                        query_lower = query.lower()
        
        # 4. ê·¼ìœ¡ëª…ì´ MUSCLE_LABELSì— ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ìˆ˜ì •
        validated_muscles_in_query = []
        for muscle in MUSCLE_LABELS:
            if muscle.lower() in query_lower:
                validated_muscles_in_query.append(muscle)
        
        # 5. ê¸°ë³¸ í‚¤ì›Œë“œ í™•ì¸ (ìš´ë™ ê´€ë ¨ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì¶”ê°€)
        exercise_keywords = ["ìš´ë™", "ê°•í™”", "ê°œë°œ", "í›ˆë ¨", "íŠ¸ë ˆì´ë‹", "ìŠ¤íŠ¸ë ˆì¹­", "íšŒë³µ"]
        has_exercise_keyword = any(keyword in query_lower for keyword in exercise_keywords)
        if not has_exercise_keyword:
            query = f"{query} ìš´ë™".strip()
            print(f"[RAG ì¿¼ë¦¬ ê²€ì¦] âš ï¸ ìš´ë™ ê´€ë ¨ í‚¤ì›Œë“œê°€ ì—†ì–´ì„œ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤")
        
        return True, query

    def _search_day_exercises_with_llm_query(
        self,
        targets: List[str],
        rag_query: Optional[str],
        profile_data: Optional[Dict[str, str]] = None,
        per_day: int = 4,
        exercise_diversity: Optional[Dict[str, Any]] = None,
        excluded_exercise_ids: Optional[Set[int]] = None,
    ) -> List[Dict[str, Any]]:
        """
        LLMì´ ìƒì„±í•œ RAG ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ìš´ë™ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            targets: íƒ€ê²Ÿ ê·¼ìœ¡ ëª©ë¡
            rag_query: LLMì´ ìƒì„±í•œ RAG ì¿¼ë¦¬
            profile_data: ì‚¬ìš©ì í”„ë¡œí•„ ë°ì´í„°
            per_day: í•˜ë£¨ë‹¹ ì¶”ì²œ ìš´ë™ ìˆ˜
            
        Returns:
            ê²€ìƒ‰ëœ ìš´ë™ ëª©ë¡
        """
        if not self.exercise_rag or not targets:
            return []
        
        filters = self._build_rag_filter_options(profile_data)
        seen_ids: Set[int] = set()
        day_exercises: List[Dict[str, Any]] = []
        
        # LLMì´ ìƒì„±í•œ ì›ë³¸ ì¿¼ë¦¬ ë¡œê·¸
        if rag_query:
            print(f"[RAG ê²€ìƒ‰] ğŸ“ LLM ìƒì„± ì›ë³¸ ì¿¼ë¦¬: {rag_query}")
        else:
            print(f"[RAG ê²€ìƒ‰] âš ï¸ LLMì´ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # RAG ì¿¼ë¦¬ ê²€ì¦ (ìš´ë™ ë„êµ¬ ì •ë³´ í¬í•¨)
        is_valid, validated_query = self._validate_rag_query(
            rag_query, targets, profile_data, exercise_diversity=exercise_diversity
        )
        
        if not is_valid or not validated_query:
            # ì¿¼ë¦¬ê°€ ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ ì¿¼ë¦¬ ìƒì„±
            print(f"[RAG ê²€ìƒ‰] âš ï¸ LLM ì¿¼ë¦¬ê°€ ìœ íš¨í•˜ì§€ ì•Šì•„ ê¸°ë³¸ ì¿¼ë¦¬ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤")
            profile_prefix = self._build_profile_prefix(profile_data)
            validated_query = f"{profile_prefix} {targets[0]} ìš´ë™".strip() if profile_prefix else f"{targets[0]} ìš´ë™"
        
        print(f"[RAG ê²€ìƒ‰] ğŸ” ê²€ì¦ëœ ê²€ìƒ‰ ì¿¼ë¦¬: {validated_query}")
        
        try:
            top_k = 12  # ì¶©ë¶„í•œ í›„ë³´ í™•ë³´
            rag_results = self.exercise_rag.search(
                validated_query,
                top_k=top_k,
                target_group_filter=filters["target_group_filter"],
                exclude_target_groups=filters["exclude_target_groups"],
                fitness_factor_filter=filters["fitness_factor_filter"],
                exclude_fitness_factors=filters["exclude_fitness_factors"],
            )
        except Exception as exc:
            print(f"[RAG ê²€ìƒ‰] âš ï¸ ê²€ìƒ‰ ì‹¤íŒ¨: {exc}")
            return []
        
        # íƒ€ê²Ÿ ê·¼ìœ¡ê³¼ ì¼ì¹˜í•˜ëŠ” ìš´ë™ í•„í„°ë§ (1ì°¨: ì •í™•íˆ ì¼ì¹˜)
        for muscle in targets:
            alias_tokens = self._expand_muscle_aliases(muscle)
            
            for item in rag_results:
                meta = item.get("metadata") or {}
                exercise_id = meta.get("exercise_id")
                if exercise_id is None:
                    continue
                
                try:
                    normalized_id = int(exercise_id)
                except (TypeError, ValueError):
                    continue
                
                if normalized_id in seen_ids:
                    continue
                
                # ì œì™¸í•  ìš´ë™ ID í™•ì¸
                if excluded_exercise_ids and normalized_id in excluded_exercise_ids:
                    continue
                
                # íƒ€ê²Ÿ ê·¼ìœ¡ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
                if not self._metadata_matches_muscle(meta.get("muscles"), alias_tokens):
                    continue
                
                normalized_meta = dict(meta)
                normalized_meta["exercise_id"] = normalized_id
                
                formatted = self._format_rag_exercise_payload(
                    normalized_meta,
                    score=item.get("score"),
                )
                day_exercises.append(formatted)
                seen_ids.add(normalized_id)
                
                if len(day_exercises) >= per_day:
                    break
            
            if len(day_exercises) >= per_day:
                break
        
        # 2ì°¨: ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ìš´ë™ì´ ë¶€ì¡±í•˜ë©´ ê´€ë ¨ ê·¼ìœ¡ë„ í¬í•¨ (ë” ë„“ì€ ë²”ìœ„)
        if len(day_exercises) < per_day:
            print(f"[RAG ê²€ìƒ‰] âš ï¸ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ìš´ë™ì´ ë¶€ì¡±í•©ë‹ˆë‹¤ ({len(day_exercises)}/{per_day}). ê´€ë ¨ ê·¼ìœ¡ ìš´ë™ë„ í¬í•¨í•©ë‹ˆë‹¤.")
            
            # ëª¨ë“  íƒ€ê²Ÿ ê·¼ìœ¡ì˜ ê´€ë ¨ ê·¼ìœ¡ í™•ì¥
            all_related_muscles = set()
            for muscle in targets:
                all_related_muscles.update(self._expand_muscle_aliases(muscle))
            
            for item in rag_results:
                if len(day_exercises) >= per_day:
                    break
                    
                meta = item.get("metadata") or {}
                exercise_id = meta.get("exercise_id")
                if exercise_id is None:
                    continue
                
                try:
                    normalized_id = int(exercise_id)
                except (TypeError, ValueError):
                    continue
                
                if normalized_id in seen_ids:
                    continue
                
                # ì œì™¸í•  ìš´ë™ ID í™•ì¸
                if excluded_exercise_ids and normalized_id in excluded_exercise_ids:
                    continue
                
                # ê´€ë ¨ ê·¼ìœ¡ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸ (ë” ë„“ì€ ë²”ìœ„)
                exercise_muscles = meta.get("muscles", [])
                if isinstance(exercise_muscles, str):
                    exercise_muscles = [m.strip() for m in exercise_muscles.split(",") if m.strip()]
                elif not isinstance(exercise_muscles, list):
                    exercise_muscles = []
                
                # ìš´ë™ì˜ ê·¼ìœ¡ ì¤‘ í•˜ë‚˜ë¼ë„ íƒ€ê²Ÿ ê·¼ìœ¡ê³¼ ê´€ë ¨ì´ ìˆìœ¼ë©´ í¬í•¨
                has_related_muscle = False
                for ex_muscle in exercise_muscles:
                    ex_muscle_lower = str(ex_muscle).strip().lower()
                    for target_muscle in all_related_muscles:
                        if target_muscle.lower() in ex_muscle_lower or ex_muscle_lower in target_muscle.lower():
                            has_related_muscle = True
                            break
                    if has_related_muscle:
                        break
                
                if not has_related_muscle:
                    continue
                
                normalized_meta = dict(meta)
                normalized_meta["exercise_id"] = normalized_id
                
                formatted = self._format_rag_exercise_payload(
                    normalized_meta,
                    score=item.get("score"),
                )
                day_exercises.append(formatted)
                seen_ids.add(normalized_id)
        
        # 3ì°¨: ì—¬ì „íˆ ë¶€ì¡±í•˜ë©´ ë” ë„“ì€ ì¿¼ë¦¬ë¡œ ì¬ê²€ìƒ‰
        if len(day_exercises) < per_day and targets:
            print(f"[RAG ê²€ìƒ‰] âš ï¸ ì—¬ì „íˆ ìš´ë™ì´ ë¶€ì¡±í•©ë‹ˆë‹¤ ({len(day_exercises)}/{per_day}). ë” ë„“ì€ ë²”ìœ„ë¡œ ì¬ê²€ìƒ‰í•©ë‹ˆë‹¤.")
            
            # ë” ê°„ë‹¨í•œ ì¿¼ë¦¬ë¡œ ì¬ê²€ìƒ‰
            fallback_query = f"{targets[0]} ìš´ë™"
            if profile_data:
                profile_prefix = self._build_profile_prefix(profile_data)
                if profile_prefix:
                    fallback_query = f"{profile_prefix} {fallback_query}"
            
            try:
                fallback_results = self.exercise_rag.search(
                    fallback_query,
                    top_k=20,  # ë” ë§ì€ í›„ë³´
                    target_group_filter=filters["target_group_filter"],
                    exclude_target_groups=filters["exclude_target_groups"],
                    fitness_factor_filter=filters["fitness_factor_filter"],
                    exclude_fitness_factors=filters["exclude_fitness_factors"],
                )
                
                for item in fallback_results:
                    if len(day_exercises) >= per_day:
                        break
                    
                    meta = item.get("metadata") or {}
                    exercise_id = meta.get("exercise_id")
                    if exercise_id is None:
                        continue
                    
                    try:
                        normalized_id = int(exercise_id)
                    except (TypeError, ValueError):
                        continue
                    
                    if normalized_id in seen_ids:
                        continue
                    
                    # ì œì™¸í•  ìš´ë™ ID í™•ì¸
                    if excluded_exercise_ids and normalized_id in excluded_exercise_ids:
                        continue
                        
                    normalized_meta = dict(meta)
                    normalized_meta["exercise_id"] = normalized_id
                    
                    formatted = self._format_rag_exercise_payload(
                        normalized_meta,
                        score=item.get("score"),
                    )
                    day_exercises.append(formatted)
                    seen_ids.add(normalized_id)
                    
            except Exception as fallback_exc:
                print(f"[RAG ê²€ìƒ‰] âš ï¸ Fallback ê²€ìƒ‰ ì‹¤íŒ¨: {fallback_exc}")
        
        # ìµœì¢…: ì—¬ì „íˆ ë¶€ì¡±í•˜ë©´ íƒ€ê²Ÿ ê·¼ìœ¡ë§Œìœ¼ë¡œ ìµœì†Œí•œì˜ ìš´ë™ í™•ë³´
        if len(day_exercises) == 0 and targets:
            print(f"[RAG ê²€ìƒ‰] âš ï¸ ìš´ë™ì´ ì „í˜€ ì—†ìŠµë‹ˆë‹¤. ìµœì†Œí•œì˜ ìš´ë™ì„ í™•ë³´í•©ë‹ˆë‹¤.")
            
            # ê°€ì¥ ê°„ë‹¨í•œ ì¿¼ë¦¬ë¡œ ìµœì†Œ 1ê°œ ì´ìƒ í™•ë³´
            minimal_query = targets[0]
            try:
                minimal_results = self.exercise_rag.search(
                    minimal_query,
                    top_k=30,
                    target_group_filter=filters["target_group_filter"],
                    exclude_target_groups=filters["exclude_target_groups"],
                    fitness_factor_filter=filters["fitness_factor_filter"],
                    exclude_fitness_factors=filters["exclude_fitness_factors"],
                )
                
                for item in minimal_results:
                    if len(day_exercises) >= max(1, per_day // 2):  # ìµœì†Œ 1ê°œ ì´ìƒ
                        break
                    
                    meta = item.get("metadata") or {}
                    exercise_id = meta.get("exercise_id")
                    if exercise_id is None:
                        continue
                    
                    try:
                        normalized_id = int(exercise_id)
                    except (TypeError, ValueError):
                        continue
                    
                    if normalized_id in seen_ids:
                        continue
                    
                    # ì œì™¸í•  ìš´ë™ ID í™•ì¸
                    if excluded_exercise_ids and normalized_id in excluded_exercise_ids:
                        continue
                    
                    normalized_meta = dict(meta)
                    normalized_meta["exercise_id"] = normalized_id
                    
                    formatted = self._format_rag_exercise_payload(
                        normalized_meta,
                        score=item.get("score"),
                    )
                    day_exercises.append(formatted)
                    seen_ids.add(normalized_id)
                    
            except Exception as minimal_exc:
                print(f"[RAG ê²€ìƒ‰] âš ï¸ ìµœì†Œ ìš´ë™ í™•ë³´ ì‹¤íŒ¨: {minimal_exc}")
        
        print(f"[RAG ê²€ìƒ‰] âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(day_exercises)}ê°œ ìš´ë™ ë°œê²¬ (ëª©í‘œ: {per_day}ê°œ)")
        
        if len(day_exercises) == 0:
            print(f"[RAG ê²€ìƒ‰] âŒ ê²½ê³ : ìš´ë™ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íƒ€ê²Ÿ ê·¼ìœ¡: {targets}")
        
        return day_exercises

    def _build_enhanced_rag_query(
        self,
        muscle: str,
        profile_prefix: str,
        exercise_diversity: Optional[Dict[str, Any]] = None,
        recovery_status: Optional[Dict[str, Any]] = None,
        target_muscles: Optional[List[str]] = None,
        underworked_muscles: Optional[List[str]] = None,
        overworked_muscles: Optional[List[str]] = None,
    ) -> str:
        """
        LLM ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜ì˜í•œ í–¥ìƒëœ RAG ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
        
        ì‚¬ìš©ì ì •ë³´ì™€ ì£¼ê°„ ë¶„ì„ ê²°ê³¼ë¥¼ ê²°í•©í•˜ì—¬ ë” ì •í™•í•œ ìš´ë™ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Args:
            muscle: íƒ€ê²Ÿ ê·¼ìœ¡ëª…
            profile_prefix: ì‚¬ìš©ì í”„ë¡œí•„ ì •ë³´ (ëŒ€ìƒ ì—°ë ¹ëŒ€, ìš´ë™ ìˆ˜ì¤€, ìš´ë™ ëª©ì )
            exercise_diversity: ìš´ë™ ë‹¤ì–‘ì„± ë¶„ì„ ê²°ê³¼
            recovery_status: íšŒë³µ ìƒíƒœ ë¶„ì„ ê²°ê³¼
            target_muscles: ì „ì²´ íƒ€ê²Ÿ ê·¼ìœ¡ ëª©ë¡
            underworked_muscles: LLMì´ ë¶„ì„í•œ ë¶€ì¡±í•œ ê·¼ìœ¡ ëª©ë¡
            overworked_muscles: LLMì´ ë¶„ì„í•œ ê³¼ì‚¬ìš© ê·¼ìœ¡ ëª©ë¡
            
        Returns:
            RAG ê²€ìƒ‰ì— ì‚¬ìš©í•  ì¿¼ë¦¬ ë¬¸ìì—´
        """
        query_parts = []
        
        # 1. ì‚¬ìš©ì í”„ë¡œí•„ ì •ë³´ í¬í•¨
        if profile_prefix:
            query_parts.append(profile_prefix)
        
        # 2. íƒ€ê²Ÿ ê·¼ìœ¡ëª… (í•µì‹¬)
        query_parts.append(muscle)
        
        # 3. ë¶€ì¡±í•œ ê·¼ìœ¡ ê°•ì¡° - LLM ë¶„ì„ ê²°ê³¼ í™œìš©
        if underworked_muscles and muscle in underworked_muscles:
            query_parts.append("ê°•í™”")
            query_parts.append("ê°œë°œ")
            # ë¶€ì¡±í•œ ê·¼ìœ¡ì€ ë” ì§‘ì¤‘ì ìœ¼ë¡œ ê²€ìƒ‰
            print(f"[RAG ì¿¼ë¦¬] ë¶€ì¡±í•œ ê·¼ìœ¡ ê°ì§€: {muscle} - ê°•í™” ìš´ë™ ê²€ìƒ‰")
        
        # 4. ê³¼ì‚¬ìš© ê·¼ìœ¡ íšŒí”¼ (í•´ë‹¹ ê·¼ìœ¡ì´ë©´ ê°€ë²¼ìš´ ìš´ë™ ê²€ìƒ‰)
        if overworked_muscles and muscle in overworked_muscles:
            query_parts.append("ê°€ë²¼ìš´")
            query_parts.append("íšŒë³µ")
            print(f"[RAG ì¿¼ë¦¬] ê³¼ì‚¬ìš© ê·¼ìœ¡ ê°ì§€: {muscle} - ê°€ë²¼ìš´ íšŒë³µ ìš´ë™ ê²€ìƒ‰")
        
        # 5. ìš´ë™ ë‹¤ì–‘ì„± ì •ë³´ ë°˜ì˜
        if exercise_diversity:
            recommended_variation = exercise_diversity.get("recommended_variation", "")
            if recommended_variation:
                # ë‹¤ì–‘ì„± ì œì•ˆì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
                if "ë‹¤ì–‘í•œ" in recommended_variation or "ë³€í™”" in recommended_variation:
                    query_parts.append("ë‹¤ì–‘í•œ")
                if "ìƒˆë¡œìš´" in recommended_variation or "ë‹¤ë¥¸" in recommended_variation:
                    query_parts.append("ìƒˆë¡œìš´")
                if "ë³€í˜•" in recommended_variation:
                    query_parts.append("ë³€í˜•")
        
        # 6. íšŒë³µ ìƒíƒœì— ë”°ë¥¸ ê°•ë„ ì¡°ì ˆ
        if recovery_status:
            suggested_intensity = recovery_status.get("suggested_intensity", "")
            fatigue_level = recovery_status.get("fatigue_level", "")
            
            if "ë‚®ìŒ" in suggested_intensity or "ë‚®ì€" in suggested_intensity or "ë‚®ìŒ" in fatigue_level:
                query_parts.append("ê°€ë²¼ìš´")
            elif "ë†’ìŒ" in suggested_intensity or "ë†’ì€" in suggested_intensity:
                query_parts.append("ê°•ë„ ë†’ì€")
            
            recovery_needs = recovery_status.get("recovery_needs", "")
            if recovery_needs and muscle in recovery_needs:
                query_parts.append("íšŒë³µ")
        
        # 7. ê¸°ë³¸ ìš´ë™ íƒ€ì… ëª…ì‹œ
        query_parts.append("ìš´ë™")
        
        query = " ".join([p for p in query_parts if p]).strip()
        
        # ìµœì†Œí•œì˜ ì¿¼ë¦¬ ë³´ì¥
        if not query or len(query) < 3:
            query = f"{muscle} ìš´ë™"
        
        print(f"[RAG ì¿¼ë¦¬] ìƒì„±ëœ ì¿¼ë¦¬: {query}")
        return query

    def _extract_recent_exercises(self, weekly_logs: List[Dict[str, Any]]) -> List[str]:
        """ì£¼ê°„ ì¼ì§€ì—ì„œ ìµœê·¼ ìˆ˜í–‰í•œ ìš´ë™ëª… ëª©ë¡ì„ ì¶”ì¶œ"""
        recent_exercises = []
        
        for log in weekly_logs:
            exercises = log.get("exercises", [])
            if not isinstance(exercises, list):
                continue
            
            for ex_data in exercises:
                if not isinstance(ex_data, dict):
                    continue
                
                exercise = ex_data.get("exercise", {})
                if not isinstance(exercise, dict):
                    continue
                
                # titleê³¼ standard_title ëª¨ë‘ ìˆ˜ì§‘
                title = exercise.get("title", "").strip()
                standard_title = exercise.get("standard_title", "").strip()
                
                if title:
                    recent_exercises.append(title)
                if standard_title and standard_title != title:
                    recent_exercises.append(standard_title)
        
        # ì¤‘ë³µ ì œê±° ë° ì •ê·œí™”
        unique_exercises = []
        seen = set()
        for ex_name in recent_exercises:
            normalized = ex_name.strip().lower()
            if normalized and normalized not in seen:
                seen.add(normalized)
                unique_exercises.append(ex_name.strip())  # ì›ë³¸ í˜•íƒœ ìœ ì§€
        
        return unique_exercises

    def _populate_daily_details_with_exercises(
        self,
        daily_details: List[Dict[str, Any]],
        profile_data: Optional[Dict[str, str]],
        fallback_muscles: Optional[List[str]] = None,
        exercise_diversity: Optional[Dict[str, Any]] = None,
    ) -> Tuple[List[int], List[Dict[str, Any]]]:
        """LLM ë£¨í‹´ ì¼ìì— RAG ìš´ë™ì„ ë§¤í•‘í•˜ê³  exercise_id ëª©ë¡ê³¼ RAG ì •ë³´ë¥¼ ë°˜í™˜"""
        if not daily_details:
            return [], []

        aggregated_ids: List[int] = []
        fallback_validated = validate_and_map_muscles(fallback_muscles or [])
        collected_sources: List[Dict[str, Any]] = []

        prepared_items: List[Tuple[Dict[str, Any], List[str], Optional[str]]] = []
        for day in daily_details:
            if not isinstance(day, dict):
                continue

            raw_targets = day.get("target_muscles") or []
            if not isinstance(raw_targets, list):
                raw_targets = []

            validated_targets = validate_and_map_muscles(raw_targets)
            if not validated_targets and fallback_validated:
                validated_targets = fallback_validated[:]

            day["target_muscles"] = validated_targets
            
            # LLMì´ ìƒì„±í•œ RAG ì¿¼ë¦¬ ê°€ì ¸ì˜¤ê¸°
            rag_query = day.get("rag_query", "").strip() if isinstance(day.get("rag_query"), str) else None
            
            prepared_items.append((day, validated_targets, rag_query))

        if not self.exercise_rag:
            return aggregated_ids, collected_sources

        # 1ë‹¨ê³„: ëª¨ë“  dayì˜ ìš´ë™ì„ ë¨¼ì € ìˆ˜ì§‘ (exercise_id, score, day_index ì €ì¥)
        day_exercise_data: List[Tuple[int, Dict[str, Any], float]] = []  # (day_index, exercise, score)
        day_index = 0
        
        for day, targets, rag_query in prepared_items:
            if not targets:
                # íƒ€ê²Ÿ ê·¼ìœ¡ì´ ì—†ìœ¼ë©´ fallback ê·¼ìœ¡ ì‚¬ìš©
                if fallback_validated:
                    targets = fallback_validated[:]
                    day["target_muscles"] = targets
                    print(f"[ë£¨í‹´ ìƒì„±] âš ï¸ Day {day.get('day', '?')}ì— íƒ€ê²Ÿ ê·¼ìœ¡ì´ ì—†ì–´ì„œ fallback ê·¼ìœ¡ ì‚¬ìš©: {targets}")
                else:
                    day["exercises"] = []
                    print(f"[ë£¨í‹´ ìƒì„±] âš ï¸ Day {day.get('day', '?')}ì— íƒ€ê²Ÿ ê·¼ìœ¡ì´ ì—†ê³  fallbackë„ ì—†ì–´ì„œ ìš´ë™ ì—†ìŒ")
                    day_index += 1
                    continue

            # LLMì´ ìƒì„±í•œ RAG ì¿¼ë¦¬ ì‚¬ìš© (ê²€ì¦ í›„)
            day_exercises = self._search_day_exercises_with_llm_query(
                targets=targets,
                rag_query=rag_query,
                profile_data=profile_data,
                per_day=4,
                exercise_diversity=exercise_diversity,
            )
            
            # ìš´ë™ì´ ì—†ìœ¼ë©´ ì¬ì‹œë„ (ë” ë„“ì€ ë²”ìœ„ë¡œ)
            if not day_exercises:
                print(f"[ë£¨í‹´ ìƒì„±] âš ï¸ Day {day.get('day', '?')}ì— ìš´ë™ì´ ì—†ìŠµë‹ˆë‹¤. ì¬ê²€ìƒ‰í•©ë‹ˆë‹¤.")
                simple_query = f"{targets[0]} ìš´ë™" if targets else None
                day_exercises = self._search_day_exercises_with_llm_query(
                    targets=targets,
                    rag_query=simple_query,
                    profile_data=profile_data,
                    per_day=4,
                    exercise_diversity=exercise_diversity,
                )
            
            # ê° ìš´ë™ì„ day_indexì™€ í•¨ê»˜ ì €ì¥
            for exercise in day_exercises:
                exercise_id = exercise.get("exercise_id")
                if isinstance(exercise_id, int):
                    score = exercise.get("score", 0.0) or 0.0
                    day_exercise_data.append((day_index, exercise, float(score)))
            
            day_index += 1

        # 2ë‹¨ê³„: ì¤‘ë³µëœ exercise_idë¥¼ ì°¾ì•„ì„œ scoreê°€ ê°€ì¥ ë†’ì€ dayì—ë§Œ ë‚¨ê¸°ê¸°
        exercise_id_to_days: Dict[int, List[Tuple[int, float]]] = {}  # exercise_id -> [(day_index, score), ...]
        
        for day_idx, exercise, score in day_exercise_data:
            exercise_id = exercise.get("exercise_id")
            if not isinstance(exercise_id, int):
                continue
            
            if exercise_id not in exercise_id_to_days:
                exercise_id_to_days[exercise_id] = []
            exercise_id_to_days[exercise_id].append((day_idx, score))
        
        # ì¤‘ë³µëœ exercise_idì— ëŒ€í•´ scoreê°€ ê°€ì¥ ë†’ì€ day ê²°ì •
        exercise_id_to_best_day: Dict[int, int] = {}  # exercise_id -> best_day_index
        exercises_to_remove: Dict[int, Set[int]] = {}  # day_index -> set of exercise_ids to remove
        
        for exercise_id, day_scores in exercise_id_to_days.items():
            if len(day_scores) > 1:  # ì¤‘ë³µëœ ê²½ìš°
                # scoreê°€ ê°€ì¥ ë†’ì€ day ì°¾ê¸°
                best_day_idx, best_score = max(day_scores, key=lambda x: x[1])
                exercise_id_to_best_day[exercise_id] = best_day_idx
                
                # ë‹¤ë¥¸ dayì—ì„œëŠ” ì œê±°
                for day_idx, score in day_scores:
                    if day_idx != best_day_idx:
                        if day_idx not in exercises_to_remove:
                            exercises_to_remove[day_idx] = set()
                        exercises_to_remove[day_idx].add(exercise_id)
                
                print(f"[ë£¨í‹´ ìƒì„±] ğŸ”„ ì¤‘ë³µ ìš´ë™ ë°œê²¬: exercise_id={exercise_id}, Day {best_day_idx}ì— ìœ ì§€ (score={best_score:.3f}), ë‹¤ë¥¸ dayì—ì„œ ì œê±°")
        
        # 3ë‹¨ê³„: ê° dayë³„ë¡œ ìµœì¢… ìš´ë™ ëª©ë¡ êµ¬ì„±
        day_index = 0
        for day, targets, rag_query in prepared_items:
            if not isinstance(day, dict):
                day_index += 1
                continue
            
            # í•´ë‹¹ dayì˜ ìš´ë™ ëª©ë¡ êµ¬ì„±
            day_exercise_ids: List[int] = []
            day_exercises_dict: Dict[int, Dict[str, Any]] = {}  # exercise_id -> exercise data
            
            # í•´ë‹¹ dayì˜ ëª¨ë“  ìš´ë™ ìˆ˜ì§‘
            for d_idx, exercise, score in day_exercise_data:
                if d_idx == day_index:
                    exercise_id = exercise.get("exercise_id")
                    if isinstance(exercise_id, int):
                        day_exercises_dict[exercise_id] = exercise
            
            # ì œê±°í•  ìš´ë™ ì œì™¸
            if day_index in exercises_to_remove:
                for exercise_id_to_remove in exercises_to_remove[day_index]:
                    if exercise_id_to_remove in day_exercises_dict:
                        del day_exercises_dict[exercise_id_to_remove]
                        print(f"[ë£¨í‹´ ìƒì„±] ğŸ—‘ï¸ Day {day.get('day', '?')}ì—ì„œ ì¤‘ë³µ ìš´ë™ ì œê±°: exercise_id={exercise_id_to_remove}")
            
            # ìµœì¢… ìš´ë™ ëª©ë¡ ìƒì„±
            for exercise_id, exercise_data in day_exercises_dict.items():
                day_exercise_ids.append(exercise_id)
                aggregated_ids.append(exercise_id)
                collected_sources.append({
                    "score": exercise_data.get("score"),
                    "metadata": exercise_data,
                })
            
            # ì œê±°ëœ ìš´ë™ì´ ìˆìœ¼ë©´ ì¶”ê°€ ê²€ìƒ‰ìœ¼ë¡œ ì±„ìš°ê¸°
            removed_count = len(exercises_to_remove.get(day_index, set()))
            if removed_count > 0 and targets:
                print(f"[ë£¨í‹´ ìƒì„±] ğŸ” Day {day.get('day', '?')}ì— {removed_count}ê°œ ìš´ë™ì´ ì œê±°ë˜ì–´ ì¶”ê°€ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
                
                # ì œì™¸í•  exercise_id ëª©ë¡
                excluded_ids = set(day_exercise_ids)  # ì´ë¯¸ í¬í•¨ëœ ìš´ë™ ì œì™¸
                for other_day_idx in range(len(prepared_items)):
                    if other_day_idx != day_index:
                        # ë‹¤ë¥¸ dayì˜ ìš´ë™ë„ ì œì™¸ (ì¤‘ë³µ ë°©ì§€)
                        for d_idx, exercise, score in day_exercise_data:
                            if d_idx == other_day_idx:
                                other_exercise_id = exercise.get("exercise_id")
                                if isinstance(other_exercise_id, int):
                                    excluded_ids.add(other_exercise_id)
                
                # ì¶”ê°€ ê²€ìƒ‰ (ì œì™¸í•  ìš´ë™ ID ì „ë‹¬)
                additional_exercises = self._search_day_exercises_with_llm_query(
                    targets=targets,
                    rag_query=rag_query,
                    profile_data=profile_data,
                    per_day=removed_count,
                    exercise_diversity=exercise_diversity,
                    excluded_exercise_ids=excluded_ids,
                )
                
                # ì œì™¸ëœ ìš´ë™ì„ ì œì™¸í•˜ê³  ì¶”ê°€
                for exercise in additional_exercises:
                    exercise_id = exercise.get("exercise_id")
                    if isinstance(exercise_id, int) and exercise_id not in excluded_ids:
                        day_exercise_ids.append(exercise_id)
                        aggregated_ids.append(exercise_id)
                        excluded_ids.add(exercise_id)  # ì¤‘ë³µ ë°©ì§€
                        collected_sources.append({
                            "score": exercise.get("score"),
                            "metadata": exercise,
                        })
                        
                        if len(day_exercise_ids) >= 4:  # per_day ì œí•œ
                            break
            
            # ìµœì¢…ì ìœ¼ë¡œë„ ìš´ë™ì´ ì—†ìœ¼ë©´ ê²½ê³ 
            if not day_exercise_ids:
                print(f"[ë£¨í‹´ ìƒì„±] âŒ Day {day.get('day', '?')}ì— ì—¬ì „íˆ ìš´ë™ì´ ì—†ìŠµë‹ˆë‹¤. íƒ€ê²Ÿ ê·¼ìœ¡: {targets}")
            
            day["exercises"] = day_exercise_ids
            day_index += 1

        return aggregated_ids, collected_sources

    def _build_muscle_analysis_from_response(
        self, parsed_response: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """LLM ë£¨í‹´ ì‘ë‹µì—ì„œ ê·¼ìœ¡ ë¶„ì„ ìš”ì•½ì„ ìƒì„±"""
        if not parsed_response:
            return None

        pattern_analysis = parsed_response.get("pattern_analysis", {}) or {}
        muscle_balance = pattern_analysis.get("muscle_balance", {}) or {}

        underworked = muscle_balance.get("underworked") or []
        overworked = muscle_balance.get("overworked") or []
        next_targets = parsed_response.get("next_target_muscles") or []

        validated_under = validate_and_map_muscles(underworked)
        validated_over = validate_and_map_muscles(overworked)
        validated_next = validate_and_map_muscles(next_targets)

        recommendation_focus = (
            pattern_analysis.get("habit_observation")
            or pattern_analysis.get("consistency")
            or pattern_analysis.get("intensity_trend")
            or ""
        )

        return {
            "underworked_muscles": validated_under,
            "overworked_muscles": validated_over,
            "next_target_muscles": validated_next,
            "recommendation_focus": recommendation_focus[:250],
        }

    def _get_rag_candidates_for_routine(
        self,
        workout_log: Dict[str, Any],
        frequency: int,
        user_profile: Optional[Dict[str, str]] = None,
        top_k: int = 6
    ) -> List[Dict[str, Any]]:
        if not self.exercise_rag:
            return []

        query = self._build_rag_query(workout_log, frequency, user_profile=user_profile)
        if not query:
            return []

        try:
            profile_data = self._clean_user_profile(user_profile)
            filters = self._build_rag_filter_options(profile_data)

            return self.exercise_rag.search(
                query, 
                top_k=top_k,
                target_group_filter=filters["target_group_filter"],
                exclude_target_groups=filters["exclude_target_groups"],
                fitness_factor_filter=filters["fitness_factor_filter"],
                exclude_fitness_factors=filters["exclude_fitness_factors"],
            )
        except Exception:
            return []

    def _build_rag_query(
        self,
        workout_log: Dict[str, Any],
        frequency: int,
        user_profile: Optional[Dict[str, str]] = None,
    ) -> str:
        exercises = workout_log.get("exercises") or []
        muscles: List[str] = []
        body_parts: List[str] = []

        for ex in exercises:
            if not isinstance(ex, dict):
                continue
            exercise_info = ex.get("exercise", {}) or {}
            muscles.extend(exercise_info.get("muscles", []) or [])
            body_part = exercise_info.get("bodyPart")
            if body_part:
                body_parts.append(body_part)

        muscles = [m for m in {m for m in muscles if m}]
        body_parts = [bp for bp in {bp for bp in body_parts if bp}]

        focus_clause = ""
        if body_parts:
            focus_clause = f"ì£¼ìš” ìš´ë™ ë¶€ìœ„: {', '.join(body_parts)}. "
        elif muscles:
            focus_clause = f"ëª©í‘œ ê·¼ìœ¡: {', '.join(muscles)}. "

        profile_parts: List[str] = []
        if user_profile:
            if user_profile.get("targetGroup"):
                profile_parts.append(f"ëŒ€ìƒ ì—°ë ¹: {user_profile['targetGroup']}")
            if user_profile.get("fitnessLevelName"):
                profile_parts.append(f"ìš´ë™ ìˆ˜ì¤€: {user_profile['fitnessLevelName']}")
            if user_profile.get("fitnessFactorName"):
                profile_parts.append(f"ìš´ë™ ëª©ì : {user_profile['fitnessFactorName']}")

        profile_clause = " ".join(profile_parts)
        frequency_clause = f"ì£¼ {frequency}íšŒ ë£¨í‹´ì— ì í•©í•œ ìš´ë™ì„ ì¶”ì²œ."

        query_parts = [focus_clause, profile_clause, frequency_clause]
        return " ".join(part for part in query_parts if part).strip()
    
    def _create_routine_recommendation_prompt(
        self, 
        workout_log: Dict[str, Any], 
        days: int, 
        frequency: int,
        rag_candidates: Optional[List[Dict[str, Any]]] = None,
        user_profile: Optional[Dict[str, str]] = None,
    ) -> str:
        """ìš´ë™ ë£¨í‹´ ì¶”ì²œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        date = workout_log.get("date", "ë‚ ì§œ ì •ë³´ ì—†ìŒ")
        exercises = workout_log.get("exercises", [])
        profile_block = self._format_user_profile_block(user_profile or {})
        
        # ê·¼ìœ¡ ê·¸ë£¹ ì¶”ì¶œ
        muscle_groups = []
        for ex_data in exercises:
            exercise = ex_data.get("exercise", {})
            muscles = exercise.get("muscles", [])
            muscle_groups.extend(muscles)
        
        unique_muscles = list(set(muscle_groups))
        
        # RAG í›„ë³´ ë°ì´í„°ë¥¼ ë©”íƒ€ë°ì´í„°ë§Œ ì¶”ì¶œí•˜ì—¬ í¬ë§·íŒ…
        candidate_payload = []
        if rag_candidates:
            for item in rag_candidates:
                meta = item.get("metadata", {}) or {}
                candidate_payload.append({
                    "score": item.get("score"),
                    "exercise_id": meta.get("exercise_id"),  # exercise_id ì¶”ê°€
                    "title": meta.get("title"),
                    "standard_title": meta.get("standard_title"),
                    "training_name": meta.get("training_name"),
                    "body_part": meta.get("body_part"),
                    "exercise_tool": meta.get("exercise_tool"),
                    "fitness_factor_name": meta.get("fitness_factor_name"),
                    "fitness_level_name": meta.get("fitness_level_name"),
                    "target_group": meta.get("target_group"),
                    "training_aim_name": meta.get("training_aim_name"),
                    "training_place_name": meta.get("training_place_name"),
                    "training_section_name": meta.get("training_section_name"),
                    "training_step_name": meta.get("training_step_name"),
                    "description": meta.get("description"),
                    "muscles": meta.get("muscles"),  # ê·¼ìœ¡ ì •ë³´ ì¶”ê°€
                    "video_url": meta.get("video_url"),
                    "video_length_seconds": meta.get("video_length_seconds"),  # video_length_seconds ì¶”ê°€
                    "image_url": meta.get("image_url"),
                    "image_file_name": meta.get("image_file_name"),  # image_file_name ì¶”ê°€
                })
        candidate_json = json.dumps(candidate_payload, ensure_ascii=False, indent=2)

        prompt = f"""
ì‚¬ìš©ìì˜ ìµœê·¼ ìš´ë™ ê¸°ë¡:
ë‚ ì§œ: {date}

[ì‚¬ìš©ì í”„ë¡œí•„]
{profile_block}

ì£¼ìš” ê·¼ìœ¡ ê·¸ë£¹:
{', '.join(unique_muscles) if unique_muscles else 'ê¸°ë¡ ì—†ìŒ'}

ì£¼ {frequency}íšŒ, {days}ì¼ê°„ì˜ ìš´ë™ ë£¨í‹´ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ìì˜ ìš´ë™ ìˆ˜ì¤€ê³¼ íŒ¨í„´ì„ ê³ ë ¤í•˜ì—¬:
- ì „ì‹  ê· í˜•ì„ ê³ ë ¤í•œ ë¶„í•  ë°©ì‹
- ì ì ˆí•œ ìš´ë™ ê°•ë„ì™€ ë¹ˆë„
- ì ì§„ì  ê³¼ë¶€í•˜ ì›ì¹™
- ì•ˆì „í•˜ê³  ì‹¤ì²œ ê°€ëŠ¥í•œ ë£¨í‹´
- ì‚¬ìš©ì í”„ë¡œí•„(targetGroup, fitnessLevelName, fitnessFactorName)ì´ ì œê³µë˜ë©´ ê·¸ ì¡°ê±´ì— ë§ëŠ” ìš´ë™ë§Œ ì„ íƒí•˜ì„¸ìš”. ì •ë³´ê°€ ì—†ìœ¼ë©´ ì¼ë°˜ì ì¸ ì•ˆì „ ê¸°ì¤€ì„ ë”°ë¥´ì„¸ìš”.
- ë°˜ë“œì‹œ ìµœì†Œ 3ì¼ ì´ìƒì˜ ë¶„í• (day 1~)ì„ êµ¬ì„±í•˜ê³ , ê° dayë§ˆë‹¤ ìµœì†Œ 3ê°œ ì´ìƒì˜ ê°ê¸° ë‹¤ë¥¸ ìš´ë™ì„ í¬í•¨í•˜ì„¸ìš”. ë‹¨ì¼ ìš´ë™ë§Œ ì¶”ì²œí•˜ì§€ ë§ˆì„¸ìš”.

ìƒì„¸í•œ ìš´ë™ëª…, ì„¸íŠ¸, íšŸìˆ˜, íœ´ì‹ì‹œê°„ê¹Œì§€ í¬í•¨í•´ì£¼ì„¸ìš”.

[ì¶”ì²œ í›„ë³´ ìš´ë™ ë°ì´í„°(JSON)]
{candidate_json}

âš ï¸ ë§¤ìš° ì¤‘ìš”: daily_routines[].exercises[] ë° suggested_exercises[] í•­ëª©ì„ ì‘ì„±í•  ë•ŒëŠ” ë°˜ë“œì‹œ ìœ„ JSON ë°°ì—´ì— ìˆëŠ” ìš´ë™ ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
- exercises ë°°ì—´ì˜ ê° í•­ëª©ì€ ìœ„ JSON ë°°ì—´ì˜ í•­ëª© ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì—¬ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
- title í•„ë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš” (name í•„ë“œëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”). titleì€ í›„ë³´ ë°ì´í„°ì˜ title ê°’ì„ ì‚¬ìš©í•˜ì„¸ìš”.
- exercise_id, video_url, video_length_seconds, image_url, body_part, exercise_tool, description, muscles, target_group, fitness_factor_name, fitness_level_name ë“± ëª¨ë“  í•„ë“œëŠ” ìœ„ JSONì—ì„œ ì œê³µëœ ê°’ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
- ìœ„ JSONì— ì—†ëŠ” ìš´ë™ëª…, video_url, image_url ë“±ì„ ì„ì˜ë¡œ ìƒì„±í•˜ê±°ë‚˜ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
- ìœ„ JSON ë°°ì—´ì— ìˆëŠ” ìš´ë™ë§Œ ì¶”ì²œí•˜ê³ , ë°°ì—´ì— ì—†ëŠ” ìš´ë™ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.
- ê° ìš´ë™ì˜ video_urlê³¼ title/standard_titleì€ ë°˜ë“œì‹œ ìœ„ JSONì—ì„œ ì œê³µëœ ìŒì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
- muscles í•„ë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš” (muscle_nameì´ ì•„ë‹™ë‹ˆë‹¤).

[ê·¼ìœ¡ ë¼ë²¨ ëª©ë¡]
ì•„ë˜ ëª©ë¡ì— í¬í•¨ëœ ê·¼ìœ¡ëª…ë§Œ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ ìš´ë™ì„ ì¶”ì²œí•  ê·¼ìœ¡(next_target_muscles)ì„ 2~5ê°œ ì„ ì •í•˜ì„¸ìš”.
ì„ ì • ê¸°ì¤€: (1) ìµœê·¼ ê¸°ë¡ì—ì„œ ë¶€ì¡±í•˜ê±°ë‚˜ ëœ ì‚¬ìš©ëœ ê·¼ìœ¡, (2) ê³¼ì‚¬ìš© ë¶€ìœ„ëŠ” í”¼í•¨, (3) ì „ì‹  ê· í˜• ê°œì„ .
{', '.join(MUSCLE_LABELS)}"""
        
        return prompt
    
    def _create_workout_analysis_prompt(self, analysis: ComprehensiveAnalysis) -> str:
        """ë¶„ì„ ê²°ê³¼ë¥¼ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜"""
        
        pattern = analysis.pattern
        
        prompt = f"""
ì‚¬ìš©ìì˜ ìš´ë™ ì¼ì§€ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤. ì´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§ì¶¤í˜• ì¡°ì–¸ì„ ì œê³µí•´ì£¼ì„¸ìš”.

[ìš´ë™ í†µê³„]
- ë¶„ì„ ê¸°ê°„: {analysis.analysis_period}
- ì´ ìš´ë™ íšŸìˆ˜: {pattern.total_workouts}ì¼
- ì´ ìš´ë™ ê°œìˆ˜: {pattern.total_exercises}ê°œ
- ì´ ìš´ë™ ì‹œê°„: {pattern.total_time}ë¶„
- í‰ê·  ìš´ë™ ì‹œê°„: {pattern.avg_workout_time}ë¶„/ì¼

[ì‹ ì²´ ë¶€ìœ„ë³„ ë¹„ìœ¨]
"""
        
        for bp in pattern.body_part_distribution:
            prompt += f"- {bp.body_part}: {bp.percentage}% ({bp.exercise_count}íšŒ)\n"
        
        prompt += f"""
[ê°€ì¥ ë§ì´ í•œ ìš´ë™]
"""
        for exercise in pattern.most_frequent_exercises[:5]:
            prompt += f"- {exercise['name']}: {exercise['count']}íšŒ ({exercise['body_part']})\n"
        
        prompt += f"""
[ìš´ë™ ê°•ë„]
- ìƒê°•ë„: {pattern.intensity_distribution['ìƒ']}ê°œ
- ì¤‘ê°•ë„: {pattern.intensity_distribution['ì¤‘']}ê°œ
- í•˜ê°•ë„: {pattern.intensity_distribution['í•˜']}ê°œ

[í˜„ì¬ ë¬¸ì œì ]
- ê³¼ì‚¬ìš© ë¶€ìœ„: {', '.join(analysis.insights.overworked_parts) if analysis.insights.overworked_parts else 'ì—†ìŒ'}
- ë¶€ì¡±í•œ ë¶€ìœ„: {', '.join(analysis.insights.underworked_parts) if analysis.insights.underworked_parts else 'ì—†ìŒ'}
- ê· í˜• ì ìˆ˜: {analysis.insights.balance_score}/100

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ í¬í•¨í•œ ë§ì¶¤í˜• ì¡°ì–¸ì„ ì œê³µí•´ì£¼ì„¸ìš”:
1. í˜„ì¬ ìš´ë™ íŒ¨í„´ì˜ ì¥ë‹¨ì  ë¶„ì„
2. ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ê³¼ êµ¬ì²´ì ì¸ ì†”ë£¨ì…˜
3. ì¶”ì²œ ìš´ë™ ë£¨í‹´
4. ì£¼ì˜ì‚¬í•­ ë° ë¶€ìƒ ì˜ˆë°© íŒ

í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ê²©ë ¤í•˜ëŠ” í†¤ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

[ê·¼ìœ¡ ë¼ë²¨ ëª©ë¡]
ì•„ë˜ ëª©ë¡ì— í¬í•¨ëœ ê·¼ìœ¡ëª…ë§Œ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ ìš´ë™ì„ ì¶”ì²œí•  ê·¼ìœ¡(next_target_muscles)ì„ 2~5ê°œ ì„ ì •í•˜ì„¸ìš”.
ì„ ì • ê¸°ì¤€: (1) ìµœê·¼ ê¸°ë¡ì—ì„œ ë¶€ì¡±í•˜ê±°ë‚˜ ëœ ì‚¬ìš©ëœ ê·¼ìœ¡, (2) ê³¼ì‚¬ìš© ë¶€ìœ„ëŠ” í”¼í•¨, (3) ì „ì‹  ê· í˜• ê°œì„ .
{', '.join(MUSCLE_LABELS)}
"""
        return prompt

    def _calculate_weekly_metrics(self, weekly_logs: List[Dict[str, Any]]) -> Dict[str, Any]:
        intensity_counts: Dict[str, int] = {"ìƒ": 0, "ì¤‘": 0, "í•˜": 0}
        body_part_counts: Dict[str, int] = {}
        muscle_counts: Dict[str, int] = {}
        equipment_counts: Dict[str, int] = {}  # ìš´ë™ ë„êµ¬ ì‚¬ìš© íšŸìˆ˜
        total_minutes = 0
        active_days = 0

        for log in weekly_logs:
            raw_exercises = log.get("exercises")

            if isinstance(raw_exercises, list):
                exercises = [ex for ex in raw_exercises if isinstance(ex, dict)]
            elif isinstance(raw_exercises, dict):
                exercises = [raw_exercises]
            else:
                exercises = []

            if exercises:
                active_days += 1

            for ex in exercises:
                intensity = ex.get("intensity", "ì¤‘")
                if intensity not in intensity_counts:
                    intensity_counts.setdefault("ê¸°íƒ€", 0)
                    intensity_counts["ê¸°íƒ€"] += 1
                else:
                    intensity_counts[intensity] += 1

                total_minutes += ex.get("exerciseTime", 0)

                exercise_info = ex.get("exercise", {})
                body_part = exercise_info.get("bodyPart") or self._infer_body_part(exercise_info)
                body_part_counts[body_part] = body_part_counts.get(body_part, 0) + 1

                for muscle in exercise_info.get("muscles", []):
                    muscle_counts[muscle] = muscle_counts.get(muscle, 0) + 1
                
                # ìš´ë™ ë„êµ¬ ì •ë³´ ìˆ˜ì§‘
                exercise_tool = exercise_info.get("exerciseTool", "")
                if exercise_tool and exercise_tool.strip() and exercise_tool != "ì •ë³´ ì—†ìŒ":
                    equipment_counts[exercise_tool] = equipment_counts.get(exercise_tool, 0) + 1

        top_muscles = [
            {"name": name, "count": count}
            for name, count in sorted(muscle_counts.items(), key=lambda item: item[1], reverse=True)
        ]
        
        top_equipment = [
            {"name": name, "count": count}
            for name, count in sorted(equipment_counts.items(), key=lambda item: item[1], reverse=True)
        ]

        # ì£¼ê°„ ë¶„ì„ì´ë¯€ë¡œ ì´ ì¼ìˆ˜ëŠ” í•­ìƒ 7ì¼ë¡œ ê³ ì •
        rest_days = max(0, 7 - active_days)

        return {
            "weekly_workout_count": active_days,
            "rest_days": rest_days,
            "total_minutes": total_minutes,
            "intensity_counts": intensity_counts,
            "body_part_counts": body_part_counts,
            "top_muscles": top_muscles,
            "top_equipment": top_equipment  # ìš´ë™ ë„êµ¬ ì •ë³´ ì¶”ê°€
        }

    def _infer_body_part(self, exercise_info: Dict[str, Any]) -> str:
        title = exercise_info.get("title", "").lower()
        description = exercise_info.get("description", "").lower()
        training_name = exercise_info.get("trainingName", "").lower()

        lower_body_keywords = [
            "ë‹¤ë¦¬", "í•˜ì²´", "ìŠ¤ì¿¼íŠ¸", "ëŸ°ì§€", "ë°ë“œ", "ë ˆê·¸", "ëŒ€í‡´", "í—ˆë²…ì§€", "ì¢…ì•„ë¦¬", "í™", "ë³¼ê¸°", "ë‘”ê·¼"
        ]
        upper_body_keywords = [
            "ê°€ìŠ´", "ì–´ê¹¨", "íŒ”", "ë“±", "ì½”ì–´", "ë³µë¶€", "ë²¤ì¹˜", "í”„ë ˆìŠ¤", "í’€ì—…", "ë«", "ë¡œìš°"
        ]

        text = " ".join(filter(None, [title, description, training_name]))

        if any(keyword in text for keyword in lower_body_keywords):
            return "í•˜ì²´"
        if any(keyword in text for keyword in upper_body_keywords):
            return "ìƒì²´"

        return "ê¸°íƒ€"

    def _create_weekly_pattern_prompt(
        self,
        weekly_logs: List[Dict[str, Any]],
        user_profile: Optional[Dict[str, str]] = None,
    ) -> Tuple[str, Dict[str, Any]]:
        """7ì¼ì¹˜ ìš´ë™ ê¸°ë¡ì„ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜"""

        if not weekly_logs:
            return (
                "ìµœê·¼ 7ì¼ê°„ì˜ ìš´ë™ ê¸°ë¡ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê°€ëŠ¥í•œ ê²½ìš° ìµœê·¼ ê¸°ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ í†µì°°ê³¼ ë£¨í‹´ì„ ì œì•ˆí•´ì£¼ì„¸ìš”.",
                {
                    "weekly_workout_count": 0,
                    "rest_days": 7,
                    "total_minutes": 0,
                    "intensity_counts": {"ìƒ": 0, "ì¤‘": 0, "í•˜": 0},
                    "body_part_counts": {},
                    "top_muscles": []
                }
            )

        metrics = self._calculate_weekly_metrics(weekly_logs)
        profile_block = self._format_user_profile_block(user_profile or {})

        intensity_summary_items = [
            f"{level} {count}íšŒ" for level, count in metrics["intensity_counts"].items()
        ]
        intensity_summary = ", ".join(intensity_summary_items) if intensity_summary_items else "ë°ì´í„° ì—†ìŒ"

        sorted_body_parts = sorted(
            metrics["body_part_counts"].items(),
            key=lambda item: item[1],
            reverse=True
        )
        body_part_summary = ", ".join(
            f"{bp} {cnt}íšŒ" for bp, cnt in sorted_body_parts[:6]
        ) if sorted_body_parts else "ë°ì´í„° ì—†ìŒ"

        top_muscle_summary = ", ".join(
            f"{entry['name']} {entry['count']}íšŒ" for entry in metrics.get("top_muscles", [])[:6]
        ) if metrics.get("top_muscles") else "ë°ì´í„° ì—†ìŒ"
        
        top_equipment_summary = ", ".join(
            f"{entry['name']} {entry['count']}íšŒ" for entry in metrics.get("top_equipment", [])[:6]
        ) if metrics.get("top_equipment") else "ë°ì´í„° ì—†ìŒ"

        prompt = f"""
ì‚¬ìš©ìì˜ ìµœê·¼ 7ì¼ ìš´ë™ ê¸°ë¡ì„ ë¶„ì„í•˜ê³ , íŒ¨í„´ì„ íŒŒì•…í•´ ì ì ˆí•œ ë£¨í‹´ì„ ì œì•ˆí•´ì£¼ì„¸ìš”.

[ì‚¬ìš©ì í”„ë¡œí•„]
{profile_block}

[7ì¼ ìš´ë™ ê¸°ë¡]
"""

        for idx, log in enumerate(weekly_logs, 1):
            date = log.get("date", "ë‚ ì§œ ì •ë³´ ì—†ìŒ")
            memo = log.get("memo", "")
            exercises = log.get("exercises", [])

            prompt += f"""
ë‚ ì§œ {idx}: {date}
ë©”ëª¨: {memo if memo else 'ë©”ëª¨ ì—†ìŒ'}
ìš´ë™ ëª©ë¡:
"""

            if not exercises:
                prompt += "- ê¸°ë¡ëœ ìš´ë™ ì—†ìŒ\n"
            else:
                    for ex_idx, ex_data in enumerate(exercises, 1):
                        exercise = ex_data.get("exercise", {})
                        muscles_list = exercise.get('muscles', [])
                        muscles_text = ', '.join(muscles_list) if muscles_list else 'ì •ë³´ ì—†ìŒ'
                        exercise_tool = exercise.get('exerciseTool', 'ì •ë³´ ì—†ìŒ')
                        # ìš´ë™ë³„ ë©”ëª¨ (ì¤‘ëŸ‰, ë°˜ë³µ íšŸìˆ˜, ì„¸íŠ¸ ìˆ˜, ì‹œê°„ ë“±)
                        exercise_memo = ex_data.get('exerciseMemo', '') or ex_data.get('memo', '')
                        exercise_memo_text = f" | ìš´ë™ ë©”ëª¨: {exercise_memo}" if exercise_memo and exercise_memo.strip() else ""
                        # ìš´ë™ ë„êµ¬ ì •ë³´ë¥¼ ëª…í™•íˆ í‘œì‹œ
                        prompt += f"- ìš´ë™ {ex_idx}: {exercise.get('title', 'ìš´ë™ëª… ì—†ìŒ')} | ì‚¬ìš© ê·¼ìœ¡: {muscles_text} | ê°•ë„: {ex_data.get('intensity', 'ì •ë³´ ì—†ìŒ')} | ì‹œê°„: {ex_data.get('exerciseTime', 0)}ë¶„ | ë„êµ¬: {exercise_tool}{exercise_memo_text} (âš ï¸ ë„êµ¬ ì •ë³´ì™€ ìš´ë™ ë©”ëª¨(ì¤‘ëŸ‰, ë°˜ë³µ, ì„¸íŠ¸ ë“±)ë¥¼ ë°˜ë“œì‹œ ë¶„ì„ì— ë°˜ì˜í•˜ì„¸ìš”)\n"

        prompt += f"""

[ì£¼ê°„ ìš”ì•½ ì§€í‘œ]
- ì£¼ê°„ ìš´ë™ íšŸìˆ˜: {metrics['weekly_workout_count']}íšŒ
- ì´ ìš´ë™ ì‹œê°„: {metrics['total_minutes']}ë¶„
- ê°•ë„ ë¶„í¬: {intensity_summary}
- ì£¼ìš” ìš´ë™ ë¶€ìœ„: {body_part_summary}
- ìƒìœ„ ê·¼ìœ¡ ì‚¬ìš©: {top_muscle_summary}
- ì£¼ìš” ì‚¬ìš© ìš´ë™ ë„êµ¬: {top_equipment_summary} (âš ï¸ ì´ ì •ë³´ë¥¼ ë°˜ë“œì‹œ ë¶„ì„ì— ë°˜ì˜í•˜ì„¸ìš”)
- íœ´ì‹ì¼ ìˆ˜: {metrics['rest_days']}ì¼

[ë¶„ì„ ë° ì¶”ì²œ ì§€ì¹¨]
1. ì£¼ê°„ ìš´ë™ ë¹ˆë„, ê°•ë„, íšŒë³µ ìƒíƒœë¥¼ ì¢…í•© ë¶„ì„
2. ê·¼ìœ¡ ì‚¬ìš©ëŸ‰ì˜ ë¶ˆê· í˜•, ê³¼ì‚¬ìš©/ë¶€ì¡± ë¶€ìœ„ë¥¼ ëª…í™•íˆ ì œì‹œ
3. âš ï¸ ë§¤ìš° ì¤‘ìš” - ìš´ë™ ë‹¤ì–‘ì„± ë¶„ì„:
   - ìµœê·¼ 7ì¼ê°„ ìˆ˜í–‰í•œ ëª¨ë“  ìš´ë™ëª…ì„ ì •í™•íˆ ì‹ë³„í•˜ê³  ë‚˜ì—´í•˜ì„¸ìš”
   - ê°™ì€ ìš´ë™ì´ ë°˜ë³µë˜ëŠ” íŒ¨í„´ì„ ë¶„ì„í•˜ì„¸ìš”
   - ìš´ë™ ë‹¤ì–‘ì„± ì ìˆ˜ë¥¼ í‰ê°€í•˜ê³  (ê°™ì€ ìš´ë™ ë°˜ë³µì´ ë§ìœ¼ë©´ ë‚®ì€ ì ìˆ˜)
   - ìš´ë™ ë‹¤ì–‘ì„±ì„ ë†’ì´ê¸° ìœ„í•œ êµ¬ì²´ì ì¸ ì œì•ˆì„ ì‘ì„±í•˜ì„¸ìš”
   - âš ï¸ ìš´ë™ë³„ ë©”ëª¨(exerciseMemo)ì— ê¸°ë¡ëœ ì¤‘ëŸ‰, ë°˜ë³µ íšŸìˆ˜, ì„¸íŠ¸ ìˆ˜, ì‹œê°„ ë“±ì˜ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì˜ ìš´ë™ ì§„í–‰ ìˆ˜ì¤€ê³¼ ê°•ë„ë¥¼ íŒŒì•…í•˜ì„¸ìš”
   - ìš´ë™ ë©”ëª¨ì˜ ì¤‘ëŸ‰/ë°˜ë³µ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ í˜„ì¬ ìš´ë™ ëŠ¥ë ¥ì„ í‰ê°€í•˜ê³ , ì ì ˆí•œ ë‹¤ìŒ ë‹¨ê³„ ìš´ë™ì„ ì¶”ì²œí•˜ì„¸ìš”
4. âš ï¸ ë§¤ìš° ì¤‘ìš” - íšŒë³µ ìƒíƒœ í‰ê°€:
   - ì£¼ê°„ ìš´ë™ ê°•ë„ì™€ ë¹ˆë„ë¥¼ ì¢…í•©í•˜ì—¬ í”¼ë¡œë„ ìˆ˜ì¤€ì„ í‰ê°€í•˜ì„¸ìš”
   - íšŒë³µì´ í•„ìš”í•œ ë¶€ìœ„ë‚˜ ê·¼ìœ¡ì„ êµ¬ì²´ì ìœ¼ë¡œ ë‚˜ì—´í•˜ì„¸ìš”
   - ë‹¤ìŒ ì£¼ ê¶Œì¥ ê°•ë„ë¥¼ ì œì‹œí•˜ì„¸ìš” (ë‚®ìŒ/ë³´í†µ/ë†’ìŒ)
5. ë‹¤ìŒ ì£¼ë¥¼ ìœ„í•œ 4~6íšŒ ë¶„í•  ë£¨í‹´ì„ êµ¬ì„±í•˜ê³  íœ´ì‹ì¼ ë˜ëŠ” ì•¡í‹°ë¸Œ ë¦¬ì»¤ë²„ë¦¬ ì œì•ˆ í¬í•¨
6. ì ì§„ì  ê³¼ë¶€í•˜ ì „ëµê³¼ ì»¨ë””ì…˜ ì¡°ì ˆ íŒ í¬í•¨
7. íšŒë³µì„ ë•ëŠ” ìƒí™œ ìŠµê´€(ìˆ˜ë©´, ì˜ì–‘, ìŠ¤íŠ¸ë ˆì¹­) ê¶Œì¥ ì‚¬í•­ ì œì‹œ
8. ì‚¬ìš©ì í”„ë¡œí•„(targetGroup, fitnessLevelName, fitnessFactorName)ì´ ì œê³µë˜ë©´ í•´ë‹¹ ì¡°ê±´ì— ì í•©í•œ ë‚œì´ë„/ìš´ë™ ì¢…ë¥˜ë§Œ ìš°ì„  ì¶”ì²œí•˜ê³ , ë¶€ì ì ˆí•œ ì¢…ëª©ì€ í”¼í•˜ì„¸ìš”.
9. ë°˜ë“œì‹œ ìµœì†Œ 3ì¼ ì´ìƒì˜ ë¶„í• ì„ êµ¬ì„±í•˜ê³ , ê° dayë§ˆë‹¤ ë°˜ë“œì‹œ ìµœì†Œ 3ê°œ ì´ìƒì˜ ê°ê¸° ë‹¤ë¥¸ ìš´ë™ì„ í¬í•¨í•˜ì„¸ìš”. ìƒì„¸í•œ ìš´ë™ëª…, ì„¸íŠ¸, íšŸìˆ˜, íœ´ì‹ì‹œê°„ê¹Œì§€ í¬í•¨í•´ì£¼ì„¸ìš”.
10. âš ï¸ ìš´ë™ ë‹¤ì–‘ì„± í™•ë³´: ìµœê·¼ ìˆ˜í–‰í•œ ìš´ë™ê³¼ ìœ ì‚¬í•œ ìš´ë™ì€ í”¼í•˜ê³ , ìƒˆë¡œìš´ ìš´ë™ ë³€í˜•ì´ë‚˜ ë‹¤ë¥¸ ê°ë„ì˜ ìš´ë™ì„ ì¶”ì²œí•˜ì„¸ìš”.

[ê·¼ìœ¡ ë¼ë²¨ ëª©ë¡]
ì•„ë˜ ëª©ë¡ì— í¬í•¨ëœ ê·¼ìœ¡ëª…ë§Œ ì‚¬ìš©í•˜ì—¬ muscle_balance.overworked, muscle_balance.underworked, next_target_muscles í•­ëª©ì„ êµ¬ì„±í•˜ì„¸ìš”.
{', '.join(MUSCLE_LABELS)}

ì¹œê·¼í•˜ê³  ê²©ë ¤í•˜ëŠ” í†¤ìœ¼ë¡œ ì‘ì„±í•˜ë˜, ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.
"""

        return prompt, metrics

    def _add_rag_to_weekly_prompt(self, prompt: str, rag_candidates: List[Dict[str, Any]]) -> str:
        """ì£¼ê°„ íŒ¨í„´ í”„ë¡¬í”„íŠ¸ì— RAG í›„ë³´ ìš´ë™ ë°ì´í„°(JSON) ì¶”ê°€"""
        if not rag_candidates:
            return prompt

        candidate_payload: List[Dict[str, Any]] = []
        for item in rag_candidates:
            meta = item.get("metadata", {}) or {}
            candidate_payload.append(
                {
                    "score": item.get("score"),
                    "exercise_id": meta.get("exercise_id"),
                    "title": meta.get("title"),
                    "standard_title": meta.get("standard_title"),
                    "training_name": meta.get("training_name"),
                    "body_part": meta.get("body_part"),
                    "exercise_tool": meta.get("exercise_tool"),
                    "fitness_factor_name": meta.get("fitness_factor_name"),
                    "fitness_level_name": meta.get("fitness_level_name"),
                    "target_group": meta.get("target_group"),
                    "training_aim_name": meta.get("training_aim_name"),
                    "training_place_name": meta.get("training_place_name"),
                    "training_section_name": meta.get("training_section_name"),
                    "training_step_name": meta.get("training_step_name"),
                    "description": meta.get("description"),
                    "muscles": meta.get("muscles"),  # ê·¼ìœ¡ ì •ë³´ ì¶”ê°€
                    "video_url": meta.get("video_url"),
                    "video_length_seconds": meta.get("video_length_seconds"),  
                    "image_url": meta.get("image_url"),
                    "image_file_name": meta.get("image_file_name"), # image_file_name ì¶”ê°€
                }
            )

        rag_section = (
            "\n\n[ì¶”ì²œ í›„ë³´ ìš´ë™ ë°ì´í„°(JSON)]\n"
            f"{json.dumps(candidate_payload, ensure_ascii=False, indent=2)}\n\n"
            "âš ï¸ ë§¤ìš° ì¤‘ìš”: recommended_routine.daily_details[].exercises[] í•­ëª©ì„ ì‘ì„±í•  ë•ŒëŠ” ë°˜ë“œì‹œ ìœ„ JSON ë°°ì—´ì— ìˆëŠ” ìš´ë™ ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.\n"
            "- exercises ë°°ì—´ì˜ ê° í•­ëª©ì€ ìœ„ JSON ë°°ì—´ì˜ í•­ëª© ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì—¬ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\n"
            "- title í•„ë“œëŠ” í›„ë³´ ë°ì´í„°ì˜ title ê°’ì„ ì‚¬ìš©í•˜ì„¸ìš” (name í•„ë“œëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”).\n"
            "- exercise_id, video_url, video_length_seconds, image_url, body_part, exercise_tool, description, muscles, target_group, fitness_factor_name, fitness_level_name, image_file_name ë“± ëª¨ë“  í•„ë“œëŠ” ìœ„ JSONì—ì„œ ì œê³µëœ ê°’ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.\n"
            "- ìœ„ JSONì— ì—†ëŠ” ìš´ë™ëª…, video_url, image_url ë“±ì„ ì„ì˜ë¡œ ìƒì„±í•˜ê±°ë‚˜ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”.\n"
            "- image_file_nameê³¼ image_urlì€ ì„œë¡œ ë‹¤ë¥¸ í•„ë“œì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ê°ê° ê°’ì„ ë„£ìœ¼ì„¸ìš”.\n"
            "- ìœ„ JSON ë°°ì—´ì— ìˆëŠ” ìš´ë™ë§Œ ì¶”ì²œí•˜ê³ , ë°°ì—´ì— ì—†ëŠ” ìš´ë™ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.\n"
            "- ê° ìš´ë™ì˜ video_urlê³¼ title/standard_titleì€ ë°˜ë“œì‹œ ìœ„ JSONì—ì„œ ì œê³µëœ ìŒì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.\n"
            "- muscles í•„ë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš” (muscle_nameì´ ì•„ë‹™ë‹ˆë‹¤).\n"
        )

        return prompt + rag_section


# ì „ì—­ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
openai_service = OpenAIService()
